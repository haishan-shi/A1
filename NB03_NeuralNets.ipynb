{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": true
    },
    "colab": {
      "name": "NB03_NeuralNets.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "3w52ilutUCa5",
        "rh48fEPwUCa6",
        "wVUTU9rjUCa6",
        "Zs6JSG2dUCa9",
        "lAxot3-VUCa-",
        "4wg130tRUCbA",
        "WN8l4UDyUCbB",
        "9m0DJ9TmUCba",
        "JO5I6XORUCbb",
        "q8U9gwapUCbh",
        "obHRTA-LUCbr",
        "mqe4e5ZBUCbu",
        "tsgt_1wgUCb0",
        "GBSmMDUNUCb0",
        "svbJbpJ1UCb3",
        "yGh3huCtUCb7",
        "y0cg1cTUUCb_",
        "o6aqq8Q_OwSr",
        "62kdUcZIRE4f",
        "BaEMt2-gVIWn",
        "QpVmM4E9MZmf",
        "io13HbPWKvX1",
        "03GP-XBAsqVi",
        "7shEN2Bts0Lj",
        "R83yfC35ujmN",
        "5oURQPW91Z9S",
        "416FAJSM4szG",
        "vtkCPCzh85fz",
        "kDcbA2g37nF2",
        "R4n7dCkr-dYo",
        "_evAuXycOwSr",
        "80iOyHdoOwSv",
        "vmk-ebdTOwS3",
        "DhA0aeIrVnTi",
        "5RlJvHgkZ2V-",
        "WuGE_KsBZ66U",
        "R4r-4x4WljfM",
        "4v_YEjH_tHsi",
        "HxYFMQeztHsj",
        "2v2uPcSrtHsn",
        "ZUx-i01AtHsq",
        "04p2-T_StHss",
        "_4wsU1KXtHst",
        "ogNi_SkVtHs0",
        "7j2ZGru1tHs1",
        "cYLbhF28tHs3",
        "h8jFF-tVtHs5",
        "Q60I8p-VtHs-",
        "h-4Fp2QwtHtA",
        "Q1P6Rht2tHtC",
        "Tfj0qsOTtHtC",
        "mhNONNBetHtE",
        "k-hNgEdntHtE",
        "xxRN2mMftHtF",
        "46E-VAMatHtG",
        "9cnjbuxQclo2"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/haishan-shi/A1/blob/master/NB03_NeuralNets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3w52ilutUCa5",
        "colab_type": "text"
      },
      "source": [
        "# 1 Basic Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rh48fEPwUCa6",
        "colab_type": "text"
      },
      "source": [
        "## 1.1 Prepare Environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVUTU9rjUCa6",
        "colab_type": "text"
      },
      "source": [
        "### 1.1.1 Library Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRXDSL7fUCa7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import torch\n",
        "import plotly.express as px\n",
        "import pandas as pd\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "Zs6JSG2dUCa9",
        "colab_type": "text"
      },
      "source": [
        "### 1.1.2 Visualisation Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "hidden": true,
        "id": "lAxot3-VUCa-",
        "colab_type": "text"
      },
      "source": [
        "#### A Simple visualiser"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "fhnum9e5UCa-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def simple_visualise(mod):\n",
        "    xx, yy = np.meshgrid(np.arange(-5, 5.01, 0.05), \n",
        "                         np.arange(-5, 5.01, 0.05))\n",
        "    xx = xx.flatten()\n",
        "    yy = yy.flatten()\n",
        "    d = pd.DataFrame(data=dict(x=xx, y=yy, \n",
        "                               z=[mod.forward((x, y)) \n",
        "                                  for x, y in zip(xx, yy)]))\n",
        "    fig = px.scatter(d, x='x', y='y', color='z')\n",
        "    fig.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4wg130tRUCbA",
        "colab_type": "text"
      },
      "source": [
        "## 1.2 Neural Networks Model Definition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WN8l4UDyUCbB",
        "colab_type": "text"
      },
      "source": [
        "### 1.2.1 Definition and Naive Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbuCeexkUCbB",
        "colab_type": "text"
      },
      "source": [
        "Let us literally translate the definition of a neural network into computer implementation:\n",
        "Neural network: Multiple _layers_ of _perceptron(s)_.\n",
        "```python\n",
        "def compute_neural_network(x):\n",
        "    # 0. prepare the input for the first layer\n",
        "    layer_input = x\n",
        "    for layer_idx in [0, 1, 2]:\n",
        "        # 1. fill output of this layer by executing each\n",
        "        #    perceptron in this layer\n",
        "        layer_output = []\n",
        "        for perceptron in net_layers[layer_idx]:\n",
        "            perceptron.compute_output(layer_input) \n",
        "            # Note all perceptrons in this layer share the same\n",
        "            # `layer_input`\n",
        "        #!!----------------------------------    \n",
        "        # 2. pass the output of THIS layer\n",
        "        #    to the NEXT layer as the input\n",
        "        #------------------------------------\n",
        "        layer_input = layer_output\n",
        "        # END OF LOOP OVER `layer_idx`\n",
        "```\n",
        "Recall that a perception is to get the weighted sum of all attributes in an input, followed by some _activation_. See below:\n",
        "```python\n",
        "def compute_perceptron(x):\n",
        "    weighted_sum = sum([xi * wi for xi, wi in zip(x, weights)])\n",
        "    return activation_function(weighted_sum)\n",
        "```\n",
        "Of course, we will need to get the weights and the activation function setup. So we will use an object class to represent both the perceptrons and the networks.\n",
        "\n",
        "NB: If you don't understand the construction `[t for t in list_of_t_values]`, please checkout tutorials about Python list."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "code_folding": [],
        "id": "Z1QMYZACUCbC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sigmoid_func(a):\n",
        "    return 1 / (1 + math.exp(-a))\n",
        "\n",
        "\n",
        "\n",
        "class Perceptron2D:\n",
        "    \"\"\"Perceptron model: linearly combine data attributes followed by a non-linear activation\n",
        "    This is a simplified implementation and deals with data with 2 attributes. \n",
        "    You can also refer to the more complete implementation in the note of Week 3.\n",
        "    \"\"\"\n",
        "    def __init__(self, w0=1, w1=0, activation_func=sigmoid_func):\n",
        "        self.w0 = w0\n",
        "        self.w1 = w1\n",
        "        self.act = activation_func\n",
        "    \n",
        "    def forward(self, x):\n",
        "        wsum = x[0] * self.w0 + x[1] * self.w1\n",
        "        sigmoid_wsum = self.act(wsum) # sigmoid for activation\n",
        "        return sigmoid_wsum\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GODTXZ5XUCbE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's have a look at how the perceptron worked on 2D data\n",
        "p = Perceptron2D(0.5, -2.5)\n",
        "simple_visualise(p)\n",
        "# Please note the effect of activation by examining the z-value."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUJOhBWpUCbJ",
        "colab_type": "text"
      },
      "source": [
        "__EXERCISE__\n",
        "\n",
        "In the code cell above, adjust the model parameters and observe the change of the model behaviour."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyIwfxtaUCbK",
        "colab_type": "text"
      },
      "source": [
        "__EXERCISE__\n",
        "\n",
        "Use a different activation function. Such as\n",
        "$$\n",
        "\\begin{align}\n",
        "y(h) = \\left\\{ \\begin{array}{c}\n",
        "0, \\textrm{ if } h \\leq 0 \\\\\n",
        "h, \\textrm{ if } h > 0\n",
        "\\end{array} \\right.\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "Add implement your activation like:\n",
        "```python\n",
        "def relu_func(h):\n",
        "    # compute y\n",
        "    # HINT: consider using `max`\n",
        "    return y\n",
        "```\n",
        "Then use your function to construct a Perceptron check the behaviour of the perceptron."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJWmN3evUCbK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def my_activation_func(h):\n",
        "    return max(0, h)\n",
        "p = Perceptron2D(0.1, -0.5, activation_func=my_activation_func)\n",
        "simple_visualise(p)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTP1EbFhUCbN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def k2(x):\n",
        "    return [xi**2 for xi in x]\n",
        "\n",
        "class Perceptron2DX:\n",
        "    \"\"\"Perceptron model wrapped. We transform the input before\n",
        "    processing them using the perceptron.\n",
        "    \"\"\"\n",
        "    def __init__(self, percep, xtransform=k2):\n",
        "        self.perceptron = percep\n",
        "        self.xtransform = xtransform\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return self.perceptron.forward(self.xtransform(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s00Np9AYUCbO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pp = Perceptron2DX(p)\n",
        "simple_visualise(pp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPBoMCovUCbR",
        "colab_type": "text"
      },
      "source": [
        "__EXERCISE__\n",
        "\n",
        "__1__:\n",
        "Use a different transform function. Such as\n",
        "$$\n",
        "\\begin{align}\n",
        "x'_1 = \\sin(\\omega_1 \\cdot x_1) \\\\\n",
        "x'_2 = \\cos(\\omega_2 \\cdot x_2)\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "__2__:\n",
        "Using your transform function on a _different perceptron core_, e.g.\n",
        "```python\n",
        "vanilla_perceptron_2 = Perceptron2D(\n",
        "        -1, 1, \n",
        "        activation_func=my_activation_func)\n",
        "pp2a = Perceptron2DX(vanilla_perceptron_2, \n",
        "                     xtransform=new_transform)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Yi6j8xVFUCbS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def new_transform(x):\n",
        "    tx0 = math.sin(x[0] * 5)\n",
        "    tx1 = math.cos(x[1])\n",
        "    return [tx0, tx1]\n",
        "\n",
        "pp2 = Perceptron2DX(p, xtransform=new_transform)\n",
        "simple_visualise(pp2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "eXNpW_lfUCbU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ly0_p0 = Perceptron2D(+1, -1, activation_func=my_activation_func)\n",
        "ly0_p1 = Perceptron2D(-1, -3, activation_func=my_activation_func)\n",
        "ly1_p = Perceptron2D(-1, 0.5, activation_func=math.tanh)\n",
        "def new_transform(x):\n",
        "    tx0 = ly0_p0.forward(x)\n",
        "    tx1 = ly0_p1.forward(x)\n",
        "    return [tx0, tx1]\n",
        "\n",
        "pp3 = Perceptron2DX(ly1_p, xtransform=new_transform)\n",
        "simple_visualise(pp3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WT9U35ihUCbX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Try yourself: can you change the parameters so \n",
        "ly0_p0 = Perceptron2D(+1, -1, activation_func=lambda x:x)\n",
        "ly0_p1 = Perceptron2D(-1, -3, activation_func=lambda x:x)\n",
        "ly1_p = Perceptron2D(-1, 0.5, activation_func=math.tanh)\n",
        "def new_transform(x):\n",
        "    tx0 = ly0_p0.forward(x)\n",
        "    tx1 = ly0_p1.forward(x)\n",
        "    return [tx0, tx1]\n",
        "\n",
        "pp3 = Perceptron2DX(ly1_p, xtransform=new_transform)\n",
        "simple_visualise(pp3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9m0DJ9TmUCba",
        "colab_type": "text"
      },
      "source": [
        "### 1.2.2 Multiple Layer Perceptron"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpM4hZ9mUCbb",
        "colab_type": "text"
      },
      "source": [
        "Alternatively (to the nested perceptrons above), we can define an NeuralNet class to hold all perceptrons in all layers. The advantage is that now we can easily extend the network to have more layers. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JO5I6XORUCbb",
        "colab_type": "text"
      },
      "source": [
        "#### Naive Implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "code_folding": [],
        "id": "QgrxLsCjUCbc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a class, so our network can manage its \"perceptrons\" easily\n",
        "class NeuralNet:\n",
        "    \"\"\"NeuralNet represents a simple neural network object class.\n",
        "    As an example, it consists of 2 layers of perceptrons. \n",
        "    The first layer has 2 perceptrons and the second one has 1.\n",
        "    \n",
        "    The perceptrons deal with data of 2 attributes.\n",
        "    \"\"\"\n",
        "    def __init__(self, perc0_w=(-1, 1), perc1_w=(2, -1), perc2_w=(0.5, 0.5)):\n",
        "        self.layers = [[Perceptron2D(*perc0_w), Perceptron2D(*perc1_w)], \n",
        "                       [Perceptron2D(*perc2_w)]] # *(w0,w1) expand the values in tuple\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Compute the network output layer by layer. \"forward\" is a conventional\n",
        "        term for execute computing of a net.\n",
        "        \"\"\"\n",
        "        # use layer-0 to process x and get what's to feed to layer-1\n",
        "        layer1_input = [p.forward(x) for p in self.layers[0]]\n",
        "        # get the final output from layer-1\n",
        "        final_output = [p.forward(layer1_input) for p in self.layers[1]]\n",
        "        # note we have only two layers, so I didn't use a loop over the layers\n",
        "        return final_output[0]\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FRvnnjLUCbe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net0 = NeuralNet()\n",
        "simple_visualise(net0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LBwem7sUCbg",
        "colab_type": "text"
      },
      "source": [
        "__EXERCISE__ (optional, similar to one above)\n",
        "\n",
        "Adjust parameters to show how the network behaviour changes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8U9gwapUCbh",
        "colab_type": "text"
      },
      "source": [
        "#### Computation using Matrix Operations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hc5Kf4WUCbh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def matmul(A, B):\n",
        "    \"\"\"\n",
        "    matmul computs A x B for two matrices\n",
        "    :param A: a collective object contains rows of a matrix\n",
        "        A[i], i-th row, another collective object contains the elements\n",
        "        A[i][j], the element\n",
        "    :param B: similar to A\n",
        "    \"\"\"\n",
        "    # figure out the size of A and B and the result\n",
        "    rows = len(A)\n",
        "    elements_inner = len(A[0])\n",
        "    assert elements_inner == len(B), \"Rows of B must be the same as Cols of A\"\n",
        "    cols = len(B[0])\n",
        "    # Initialise C to the appropriate size\n",
        "    C = [[0.0 for ci in range(cols)] for ri in range(rows)]\n",
        "    \n",
        "    # Fill C: 2 outer loops are for each element\n",
        "    for r in range(rows):\n",
        "        for c in range(cols):\n",
        "            # Compute element [i][j]\n",
        "            for k in range(elements_inner):\n",
        "                C[r][c] += A[r][k] * B[k][c]\n",
        "    return C"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hq8IOPczUCbj",
        "colab_type": "text"
      },
      "source": [
        "HINT: read the code and try it while watching the accompany video."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIYdsnCtUCbj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a class, so our network can manage its \"perceptrons\" easily\n",
        "class NeuralNetV2:\n",
        "    \"\"\"NeuralNetV2 represents a simple neural network object class.\n",
        "    This object will manage all the neurons in the network. \n",
        "    \"\"\"\n",
        "    def __init__(self, neuron_numbers_in_layers=[2, 2, 1],\n",
        "                 weights=None):\n",
        "        \"\"\"\n",
        "        :param neuron_numbers_in_layers: first/last -- inputs and outputs\n",
        "        :param weights: a dict, weights[\"in0out1\"] represents the weights\n",
        "          for computing layer1 from layer0, if layer0 has 3 inputs and layer1\n",
        "          has 2 outputs, then the weight will be a matrix of 3 x 2, i.e.\n",
        "          weights[\"in0out1\"][i][j] is the weight for computing element-j in layer1\n",
        "          by using element-i in layer0.\n",
        "        \"\"\"\n",
        "        # Weights between \n",
        "        # Layer1 and 2, Layer 2 and 3, ...\n",
        "        \n",
        "        self.weights = dict()\n",
        "        self.activ_fn = dict()\n",
        "        self.neuron_nums = neuron_numbers_in_layers\n",
        "        self.layer_num = len(neuron_numbers_in_layers) - 1\n",
        "        \n",
        "        # DEFINE (!not DO!, we dont have input X now) computation between layers\n",
        "        for l_in in range(self.layer_num):\n",
        "            l_out = l_in + 1\n",
        "            pkey = f\"in{l_in}out{l_out}\"\n",
        "            try:\n",
        "                # try to use provided weight\n",
        "                W = weights[pkey] # NOTE: should copy\n",
        "            except:\n",
        "                # if not provided ...\n",
        "                n_in = neuron_numbers_in_layers[l_in]\n",
        "                n_out = neuron_numbers_in_layers[l_out]\n",
        "                W = [[random.gauss(0, 0.1) for j in range(n_out)] \n",
        "                     for i in range(n_in)] # see init above\n",
        "            self.weights[pkey] = W\n",
        "            self.activ_fn[pkey] = math.tanh # you may want to try your own\n",
        "\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        DO computations:\n",
        "        \n",
        "        Compute the network output layer by layer. \"forward\" is a conventional\n",
        "        term for execute computing of a net.\n",
        "        :param x: a list of list: x[i], sample-i, having a number of input attributes\n",
        "          if you have only one sample, input it as \n",
        "              [[0, 1, 0]], \n",
        "              NOT [0, 1, 0]\n",
        "        \"\"\"\n",
        "        layer_input = x\n",
        "        for l_in in range(self.layer_num):\n",
        "            # Use layer-in to process x and get what's to feed to layer-out\n",
        "            # Setup \n",
        "            l_out = l_in + 1\n",
        "            pkey = f\"in{l_in}out{l_out}\"\n",
        "            # Compute the weighted sum \n",
        "            layer_pre_activation = matmul(layer_input, self.weights[pkey])\n",
        "            # Perform activation(the construction below is equivalent to nested loops)\n",
        "            layer_out = list(map(lambda x_:list(map(self.activ_fn[pkey], x_)), \n",
        "                            layer_pre_activation))\n",
        "            layer_input = layer_out # feed the output of this layer to the next layer\n",
        "        return layer_out\n",
        "    \n",
        "    \n",
        "class VisWrap:\n",
        "    \"Wrap I/O for the new network object for visualisation\"\n",
        "    def __init__(self, nn):\n",
        "        self.nn = nn\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return self.nn.forward([x])[0][0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYS7V1skUCbk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nn2 = NeuralNetV2()\n",
        "nn2_wrap = VisWrap(nn2)\n",
        "simple_visualise(nn2_wrap)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9LkqT8fUCbo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's try to adjust the weights. Carefully keep the number of weights \n",
        "# consistent with the number of neurons you had set to the layers.\n",
        "nn2 = NeuralNetV2(\n",
        "    neuron_numbers_in_layers=[2, 3, 1],\n",
        "    weights={\"in0out1\":[[0, 0.5, 1], [-1, -5, 2]],\n",
        "             \"in1out2\":[[-1], [+1], [0.5]]})\n",
        "nn2.activ_fn[\"in1out2\"] = lambda x:max(0, x)\n",
        "nn2_wrap = VisWrap(nn2)\n",
        "simple_visualise(nn2_wrap)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obHRTA-LUCbr",
        "colab_type": "text"
      },
      "source": [
        "## 1.3 Training Neural Nets via Backprop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PoM3OtvlUCbs",
        "colab_type": "text"
      },
      "source": [
        "It is not trivial to come up with a simple rule to adjust all the parameters in the entire neural network stucture (recall when we consider a single perceptron, we did propose intuitive scheme to improve the fitness of the model to data). \n",
        "\n",
        "The idea is to take a divide-and-conquer scheme. Let's take a careful look at the computation in one perceptron. Throw the machine learning terminology in wind and focus on the computation steps only.\n",
        "$$\n",
        "\\begin{align}\n",
        "a &\\leftarrow w_0 \\cdot x_0 + w_1 \\cdot x_1 \\\\\n",
        "h &\\leftarrow g(a) \\\\\n",
        "Loss &\\leftarrow Compare(h, y)\n",
        "\\end{align}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ad2TNJ2dUCbt",
        "colab_type": "text"
      },
      "source": [
        "Let us think about the statement \"to make the loss smaller\" with a bit care: which specific means we could possibily take to \"make\" the final loss change? During training, we change the model parameters, including $w_{i,j}$. So we need to know the influence on the final loss of each model parameter. In this section we will examine an example of so-called \"backpropagation\" process."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqe4e5ZBUCbu",
        "colab_type": "text"
      },
      "source": [
        "### 1.3.1 Adjust Parameters to Modify Model Behaviour"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISZfJ4-HUCbu",
        "colab_type": "text"
      },
      "source": [
        "Given training data $\\{(x_1, y_1), (x_2, y_2), \\dots\\}$, we would like the net to predict for each $x_i$ the target value $y_i$. If this is the case, then our mission has completed. Of course, this is generally NOT the case if we start from a random set of model parameters.\n",
        "\n",
        "For example, if we have one training sample $(x=(2.5, 2), y=1.0)$, let us compare the prediction given by the network above and the target value $y=1.0$: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4snoSyCUCbu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# First, check the current output of the net\n",
        "def sigm(x):\n",
        "    return 1/(1+math.exp(-x))\n",
        "\n",
        "nn2 = NeuralNetV2(\n",
        "    neuron_numbers_in_layers=[2, 3, 1],\n",
        "    weights={\"in0out1\":[[0, 0.5, 1], [-1, -5, 2]],\n",
        "             \"in1out2\":[[-1], [+1], [0.5]]})\n",
        "nn2.activ_fn[\"in0out1\"] = sigm\n",
        "nn2.activ_fn[\"in1out2\"] = sigm\n",
        "\n",
        "nn2_wrap = VisWrap(nn2)\n",
        "simple_visualise(nn2_wrap)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_DrB23dUCbx",
        "colab_type": "text"
      },
      "source": [
        "Let's check the nets behaviour at one data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6B6nQhHUCbx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nn2.forward([(2.5, 2)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZUBpvC5UCbz",
        "colab_type": "text"
      },
      "source": [
        "This is smaller than the desired output 1.0. So we want the output to increase at this $x$. Let's learn how to adjust the network using gradients computed through backprop."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tsgt_1wgUCb0",
        "colab_type": "text"
      },
      "source": [
        "### 1.3.2 Manual Backprop Through Layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBSCj4bcUCb0",
        "colab_type": "text"
      },
      "source": [
        "Let us implement the backpropagation for a three layer simple net. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "GBSmMDUNUCb0",
        "colab_type": "text"
      },
      "source": [
        "#### Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "G7tCzam4UCb1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##############################################################\n",
        "# HELPER FUNCTIONS\n",
        "# You do NOT need to learn those to USE modern neural networks\n",
        "# Those functions provide basic array functions in LOW efficiency\n",
        "# but clear manner. You may want to check them if you want to\n",
        "# UNDERSTAND the technical details of NN.\n",
        "# --------\n",
        "# First define sigmoid gradient\n",
        "import math\n",
        "def sigm(x): # redefine here for reference\n",
        "    return 1/(1+math.exp(-x))\n",
        "\n",
        "def gsigmoid(x):\n",
        "    return math.exp(-x)/(1+math.exp(-x))**2\n",
        "\n",
        "def elementwise_apply(f, nested_list):\n",
        "    return list(map(lambda x_:list(map(f, x_)), nested_list))\n",
        "\n",
        "def elementwise_times(nested_list1, nested_list2):\n",
        "    return [[a * b for a, b in zip(r1, r2)] \n",
        "            for r1, r2 in zip(nested_list1, nested_list2)]\n",
        "\n",
        "def mat_tr(nested_list):\n",
        "    return [c for c in zip(*nested_list)]\n",
        "\n",
        "def shape(nested_list):\n",
        "    return len(nested_list), len(nested_list[0])\n",
        "##############################################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "HvEZwbwcUCb2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# UNIT Test: gsigmoid -- Test the others.\n",
        "test_x = [-3, -1, 0, 1, 3, 5]\n",
        "test_eps = 1e-4\n",
        "for x_ in test_x:\n",
        "    numerical_diff = (sigm(x_ + test_eps) - sigm(x_)) / test_eps\n",
        "    analytic_diff = gsigmoid(x_)\n",
        "    print(f\"NumDiff: {numerical_diff:.3f} ~ AnaDiff: {analytic_diff:.3f}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svbJbpJ1UCb3",
        "colab_type": "text"
      },
      "source": [
        "#### Backprop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FAax_r8UCb4",
        "colab_type": "text"
      },
      "source": [
        "Below I explicily write out the forward method followed by a backward computation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mUDgRuaUCb4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def special_forward(nn, x):\n",
        "    \"\"\"\n",
        "    This is a special version for manual implementing and testing the backpropagation algorithm. \n",
        "    We only use the network \n",
        "    We don't use the computation and activation of network `nn` \n",
        "    \"\"\"\n",
        "    \n",
        "    # Copy-and-paste and simplify forward computation here:\n",
        "    layer1_input = x\n",
        "    layer1_pre_activation = matmul(layer1_input, nn.weights[\"in0out1\"])\n",
        "    layer1_out = elementwise_apply(sigm, layer1_pre_activation)\n",
        "    \n",
        "    layer2_input = layer1_out # feed the output of this layer to the next layer\n",
        "    \n",
        "    layer2_pre_activation = matmul(layer2_input, nn.weights[\"in1out2\"])\n",
        "    layer2_out = elementwise_apply(sigm, layer2_pre_activation)\n",
        "\n",
        "    layer2_pre_activation_g = elementwise_apply(gsigmoid, layer2_pre_activation)\n",
        "    w12_g = matmul(mat_tr(layer2_input), layer2_pre_activation_g)\n",
        "    layer1_out_g = matmul(layer2_pre_activation_g, mat_tr(nn.weights[\"in1out2\"]))\n",
        "    layer1_pre_activation_g = elementwise_times(\n",
        "        elementwise_apply(gsigmoid, layer1_pre_activation),\n",
        "        layer1_out_g)\n",
        "    w01_g = matmul(mat_tr(layer1_input), layer1_pre_activation_g)\n",
        "\n",
        "    return layer2_out, w01_g, w12_g\n",
        "    \n",
        "# TODO: Mark this somewhere else: this Les Mis is FUNNY! https://www.youtube.com/watch?v=dF495ERjRUo"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Hohj248UCb5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "out, w01_g, w12_g = special_forward(nn2, [[2.5, 2]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGh3huCtUCb7",
        "colab_type": "text"
      },
      "source": [
        "#### Numerical verification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OE5A0QRzUCb7",
        "colab_type": "text"
      },
      "source": [
        "Next, let us check element by element how does our backprop work. The plan is to adjust each adjustable parameter a bit and check the change of the final output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGcWdVXwUCb8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test adjusting weights in0out1\n",
        "wkey = \"in0out1\"\n",
        "w_rows, w_cols = shape(nn2.weights[wkey])\n",
        "numerical_g = [[0 for c in range(w_cols)] for r in range(w_rows)]\n",
        "test_eps = 1e-4\n",
        "test_x = [[2.5, 2]]\n",
        "old_out = nn2.forward(test_x)\n",
        "\n",
        "for r in range(w_rows):\n",
        "    for c in range(w_cols):\n",
        "        old_value = nn2.weights[wkey][r][c] # save the old value to put back after test        \n",
        "        nn2.weights[wkey][r][c] += test_eps\n",
        "        new_out = nn2.forward(test_x)\n",
        "        diff = new_out[0][0] - old_out[0][0] # check the effect of adjusting the corresponding parameter\n",
        "        numerical_g[r][c] = diff / test_eps\n",
        "        # put the old value back\n",
        "        nn2.weights[wkey][r][c] = old_value\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RkoCqkIUCb9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"numerical differential\")\n",
        "print(numerical_g)\n",
        "print(\"analytical differential\")\n",
        "print(w01_g)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0DgWKygUCb-",
        "colab_type": "text"
      },
      "source": [
        "__EXECISE__ [Optional]\n",
        "\n",
        "1. Read the code and Explain what you had observed.\n",
        "2. Check the computation for weights transforms data from layer 1 to 2.\n",
        "3. Integrate the backpropagation function into the network class.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0cg1cTUUCb_",
        "colab_type": "text"
      },
      "source": [
        "### 1.3.3 Using Computational Framework"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysVa4MDTUCb_",
        "colab_type": "text"
      },
      "source": [
        "Modern framework allows us to easily perform all the steps above. The example above can be reformulated as"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NS8l1zsYUCb_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XVWg7U5UCcA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyNN(nn.Module):\n",
        "    def __init__(self, neuron_numbers_in_layers=[2, 3, 1]):\n",
        "        super(MyNN, self).__init__()\n",
        "        \n",
        "        self.layers = nn.ModuleList(\n",
        "            [nn.Linear(in_features=nin, out_features=nout)\n",
        "             for nin, nout in zip(neuron_numbers_in_layers[:-1], \n",
        "                                  neuron_numbers_in_layers[1:])])\n",
        "        \n",
        "    def forward(self, x):\n",
        "        h = x\n",
        "        for l in self.layers:\n",
        "            h = torch.tanh(l(h))\n",
        "        return h\n",
        "    \n",
        "class TorchVisWrap:\n",
        "    def __init__(self, nn):\n",
        "        self.nn = nn\n",
        "    def forward(self, x):\n",
        "        y = self.nn(torch.Tensor(x).unsqueeze(dim=0))\n",
        "        return y.item()\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-7qONAUUCcC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.manual_seed(42)\n",
        "nn3 = MyNN([2, 6, 1])\n",
        "nn3_wrap = TorchVisWrap(nn3)\n",
        "simple_visualise(nn3_wrap)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WdZnca_UCcG",
        "colab_type": "text"
      },
      "source": [
        "Let us perform training, call it changing a neural network behaviour or searching in the hypotheses space of neural networks, it is up to your viewpoint. Eg. We want the net to generate\n",
        "    + for (4, -4)\n",
        "    - for (4, 4)\n",
        "    + for (-4, 4)\n",
        "    - for (-4, -4)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0K9PtCKUCcG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.optim import Adam\n",
        "optim = Adam(nn3.parameters(), lr=0.01) # manager: adjust params according to grads"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRTdCbaVUCcH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_steps = 50\n",
        "visualise_every_n_steps = 10\n",
        "trn_X = torch.Tensor([[4, -4], [4, 4], [-4, 4], [-4, -4]])\n",
        "trn_y = torch.Tensor([[1.0], [-1.0], [1.0], [-1.0]])\n",
        "for it in range(train_steps):\n",
        "    loss = ((trn_y - nn3(trn_X))**2).sum()\n",
        "    optim.zero_grad() # reset gradients (to clear computed gradients from previous steps)\n",
        "    loss.backward() # In one stroke, all gradients are computed!\n",
        "    optim.step()  # apply the gradients to the parameters\n",
        "    if it % visualise_every_n_steps == 0:\n",
        "        # Check the effect\n",
        "        simple_visualise(nn3_wrap)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6aqq8Q_OwSr",
        "colab_type": "text"
      },
      "source": [
        "# 2 Deep NN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62kdUcZIRE4f",
        "colab_type": "text"
      },
      "source": [
        "## 2.0 Prepare Environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaEMt2-gVIWn",
        "colab_type": "text"
      },
      "source": [
        "### Prepare LaTeX and other rendering software."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "645AA4YLehiZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget -qO- \"https://yihui.name/gh/tinytex/tools/install-unx.sh\" | sh\n",
        "!/root/bin/tlmgr install standalone preview babel-english setspace doublestroke relsize jknapltx rsfs fundus-calligra wasysym xcolor ragged2e physics microtype platex-tools ms\n",
        "!/root/bin/tlmgr install dvisvgm\n",
        "!ln -s /root/.TinyTeX/bin/x86_64-linux/dvisvgm /usr/bin/\n",
        "!ln -s /root/bin/latex /usr/bin/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMnbiYpTEF_R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "    import cairo\n",
        "except ImportError:\n",
        "    !apt-get install libcairo2-dev\n",
        "    !pip3 install pycairo\n",
        "try:\n",
        "    from manimlib.scene.scene import Scene\n",
        "except ImportError:    \n",
        "    !pip install manimlib\n",
        "\n",
        "import math\n",
        "import random\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXWN4njELQLK",
        "colab_type": "text"
      },
      "source": [
        "Renderable video in notebook.\n",
        "\n",
        "Use\n",
        "\n",
        "https://stackoverflow.com/questions/57377185/how-play-mp4-video-in-google-colab\n",
        "\n",
        "to make\n",
        "\n",
        "https://github.com/krassowski/jupyter-manim/blob/master/jupyter_manim/__init__.py\n",
        "\n",
        "work in colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uHIlOW9Knuo",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "import os\n",
        "import sys\n",
        "from contextlib import ExitStack, suppress, redirect_stdout, redirect_stderr\n",
        "from io import StringIO\n",
        "from pathlib import Path\n",
        "from tempfile import NamedTemporaryFile\n",
        "from unittest.mock import patch\n",
        "from warnings import warn\n",
        "\n",
        "import manimlib\n",
        "from IPython import get_ipython\n",
        "from IPython.core.magic import Magics, magics_class, cell_magic\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "\n",
        "import json\n",
        "\n",
        "\n",
        "_renderer_code = \"\"\"\n",
        "from manimlib.imports import *\n",
        "import copy\n",
        "import json\n",
        "with open(\"tmpscript.json\", \"r\") as f:\n",
        "    vscript = json.load(f)\n",
        "\n",
        "def add_list_to_dict(d, k, l):\n",
        "    if d.get(k) is None:\n",
        "        d[k] = l\n",
        "    else:\n",
        "        d[k] += l\n",
        "        \n",
        "class RendererMAnimV2(Scene):\n",
        "    CONFIG = {\n",
        "        \"x_min\": -4,\n",
        "        \"x_max\": 4,\n",
        "        \"y_min\": -3,\n",
        "        \"y_max\": 3,\n",
        "    }\n",
        "\n",
        "    def construct(self):\n",
        "        ######Code######\n",
        "        #Making shapes\n",
        "        gobjs = {}\n",
        "        anims = []\n",
        "        # first pass, analysis graph links and arrange the graph\n",
        "\n",
        "        \n",
        "        node_create_anim = {}\n",
        "        value_ready_anim = {}\n",
        "        forward_anim = {}\n",
        "        message_ready_anim = {}\n",
        "        backward_anim = {}\n",
        "\n",
        "        for a in vscript:\n",
        "            if a['graph_object_type'] in [\"DataNode\", \"OpNode\"]:\n",
        "                a['x'] = -4 + 8 * a['x']\n",
        "                a['y'] = -3 + 6 * a['y']\n",
        "\n",
        "\n",
        "        for a in vscript:\n",
        "            if a['graph_object_type'] == \"DataNode\":\n",
        "                # Create a data node\n",
        "                g = Circle(radius=0.2, color=WHITE)\\\n",
        "                    .shift(np.array([a['x'], a['y'], 0]))\n",
        "                data_val = a['data']\n",
        "                g_data = TextMobject(f\"{data_val:.3g}\")\\\n",
        "                    .scale(0.5)\\\n",
        "                    .shift(g.get_corner(UR))\n",
        "                gobjs[a['nodeid']] = g\n",
        "                gobjs[a['nodeid']+'_data'] = g_data\n",
        "                \n",
        "\n",
        "                if a['text'] == a['nodeid']: # no-name\n",
        "                    g_t = TextMobject(a['nodeid'])\\\n",
        "                        .next_to(g, UP).scale(0.3)\\\n",
        "                        .set_color(\"#00ff00\")\n",
        "                else:\n",
        "                    g_t = TextMobject(a['text'])\\\n",
        "                        .shift(g.get_center()).scale(0.4)\n",
        "                create_animations_1 = [\n",
        "                    ShowCreation(g), \n",
        "                    Write(g_t)]\n",
        "\n",
        "                from_id = a['from_ids'][0]\n",
        "                g_from = gobjs.get(from_id)\n",
        "                if g_from is None:\n",
        "                    create_animations_2 = [ShowCreation(g_data)]\n",
        "                else:\n",
        "                    g_from_resu = gobjs[from_id+'_resu']\n",
        "                    g_link = Line(g_from.get_edge_center(RIGHT), \n",
        "                        g.get_edge_center(LEFT))\n",
        "                    create_animations_2 = [\n",
        "                        FadeOutAndShift(g_from_resu, \n",
        "                            g.get_center() - g_from_resu.get_center()),\n",
        "                        ShowCreation(g_link),\n",
        "                        ShowCreation(g_data),\n",
        "                    ]\n",
        "\n",
        "                if a['animation_type'] == \"Create\":\n",
        "                    anims += [create_animations_1, create_animations_2]\n",
        "                    agrp = a['depend_ord']\n",
        "                    add_list_to_dict(node_create_anim, agrp, create_animations_1)\n",
        "                    add_list_to_dict(value_ready_anim, agrp, create_animations_2)\n",
        "                    \n",
        "\n",
        "            elif a['graph_object_type'] == \"OpNode\":\n",
        "                g = Square(side_length=0.2, color=GREEN)\\\n",
        "                    .shift(np.array([a['x'], a['y'], 0]))\n",
        "                g_t = TextMobject(a['text'])\\\n",
        "                    .shift(g.get_center()).scale(0.4)\n",
        "                gobjs[a['nodeid']] = g\n",
        "\n",
        "                op_create_animations = [ShowCreation(g), Write(g_t)]\n",
        "                for from_id in a['from_ids']:\n",
        "                    g_from = gobjs[from_id]\n",
        "                    g_link = Line(\n",
        "                        g_from.get_edge_center(RIGHT), \n",
        "                        g.get_edge_center(LEFT))\n",
        "                    op_create_animations.append(ShowCreation(g_link))\n",
        "\n",
        "                if a['animation_type'] == \"Create\":\n",
        "                    anims.append(op_create_animations)\n",
        "                    agrp = a['depend_ord']\n",
        "                    add_list_to_dict(node_create_anim, agrp, op_create_animations)\n",
        "\n",
        "            elif a['graph_object_type'] == \"Link\":\n",
        "                g_from = gobjs[a['from_id']] #type: Mobject\n",
        "                g_to = gobjs[a['to_id']]\n",
        "                g = Line(g_from.get_edge_center(RIGHT), g_to.get_edge_center(LEFT))\n",
        "                gobjs[(a['from_id'], a['to_id'])] = g\n",
        "                if a['animation_type'] == \"Create\":\n",
        "                    anims[-1] += [ShowCreation(g)]\n",
        "\n",
        "            elif a['graph_object_type'] == \"Message\":\n",
        "                # animate inputs\n",
        "                input_message_animations = []\n",
        "                output_data_animations = []\n",
        "                for va_out, to_id in zip(a['out_values'], a['to_ids']):\n",
        "                    for va_in, from_id in zip(a['in_values'], a['from_ids']):\n",
        "                        g_to = gobjs[to_id]\n",
        "                        g_input_data_cp = copy.deepcopy(gobjs[from_id+'_data'])\n",
        "                        \n",
        "                        input_message_animations.append(\n",
        "                            FadeOutAndShift(g_input_data_cp, \n",
        "                                g_to.get_center() - g_input_data_cp.get_center())\n",
        "                        )\n",
        "                        \n",
        "                    g_output_resu = TextMobject(f\"{va_out:.3g}\")\\\n",
        "                        .scale(0.5)\\\n",
        "                        .shift(g_to.get_corner(UR))\n",
        "\n",
        "                    output_data_animations.append(\n",
        "                        ShowCreation(g_output_resu)\n",
        "                    )\n",
        "                    gobjs[to_id+'_resu'] = g_output_resu \n",
        "                \n",
        "                if a['animation_type'] == \"Forward\":\n",
        "                    anims.append(input_message_animations)\n",
        "                    anims.append(output_data_animations)\n",
        "                    agrp = a['depend_ord']\n",
        "                    add_list_to_dict(forward_anim, agrp, input_message_animations)\n",
        "                    add_list_to_dict(value_ready_anim, agrp, output_data_animations)\n",
        "\n",
        "\n",
        "            elif a['graph_object_type'] == \"GradNode\":\n",
        "                g_node_id = a['nodeid']\n",
        "                g_grad_id = g_node_id + '_grad'\n",
        "                g_grad_old = gobjs.get(g_grad_id)\n",
        "\n",
        "                grad_val = a['grad']\n",
        "                g_node = gobjs[g_node_id] # type: Mobject\n",
        "                g_grad_new = TextMobject(f\"{grad_val:.3g}\")\\\n",
        "                    .scale(0.5)\\\n",
        "                    .shift(g_node.get_corner(UL))\n",
        "                gobjs[g_grad_id] = g_grad_new\n",
        "\n",
        "                grad_node_anim = ShowCreation(g_grad_new) if g_grad_old is None \\\n",
        "                    else Transform(g_grad_old, g_grad_new)\n",
        "\n",
        "                if a['animation_type'] == \"Create\":\n",
        "                    anims.append([grad_node_anim])\n",
        "                    agrp = a['depend_ord']\n",
        "                    add_list_to_dict(message_ready_anim, agrp, [grad_node_anim])\n",
        "\n",
        "            elif a['graph_object_type'] == \"GMessage\":\n",
        "                bprop_animations = []\n",
        "                g_from = gobjs[a['from_ids'][0]]\n",
        "                for va, to_id in zip(a['values'], a['to_ids']):\n",
        "                    g_to = gobjs[to_id]\n",
        "                    g_back_message = TextMobject(f\"{va:.3g}\")\\\n",
        "                        .scale(0.5)\\\n",
        "                        .shift(g_from.get_corner(UL))\n",
        "                    bprop_animations.append(\n",
        "                        FadeOutAndShift(g_back_message,\n",
        "                            g_to.get_corner(UR) - g_back_message.get_center())\n",
        "                    )\n",
        "                anims.append(bprop_animations)\n",
        "                agrp = a['depend_ord']\n",
        "                add_list_to_dict(backward_anim, agrp, bprop_animations)\n",
        "            else:\n",
        "                pass\n",
        "\n",
        "\n",
        "\n",
        "        #Showing shapes\n",
        "        play_short = True\n",
        "        if play_short:\n",
        "            agroups = sorted(np.unique([_['depend_ord'] for _ in vscript]))\n",
        "            for agrp in agroups:\n",
        "                for anim_type in \\\n",
        "                    [node_create_anim, forward_anim, value_ready_anim]:\n",
        "                    if anim_type.get(agrp) is not None:\n",
        "                        self.play(*anim_type[agrp])\n",
        "            for agrp in reversed(agroups):\n",
        "                for anim_type in [backward_anim, message_ready_anim]:\n",
        "                    if anim_type.get(agrp) is not None:\n",
        "                        self.play(*anim_type[agrp])\n",
        "        else:\n",
        "            for a in anims:\n",
        "                self.play(*a)\n",
        "\"\"\"\n",
        "\n",
        "__version__ = 0.11\n",
        "\n",
        "std_out = sys.stdout\n",
        "\n",
        "\n",
        "def video(path, width=854, height=480, controls=True, autoplay=True):\n",
        "    mp4 = open(path,'rb').read()\n",
        "    data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "\n",
        "    return HTML(f\"\"\"\n",
        "    <video\n",
        "      width=\"{width}\"\n",
        "      height=\"{height}\"\n",
        "      autoplay=\"{'autoplay' if autoplay else ''}\"\n",
        "      {'controls' if controls else ''}\n",
        "    >\n",
        "        <source src=\"{data_url}\" type=\"video/mp4\">\n",
        "    </video>\n",
        "    \"\"\")\n",
        "\n",
        "\n",
        "class StringIOWithCallback(StringIO):\n",
        "\n",
        "    def __init__(self, callback, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.callback = callback\n",
        "\n",
        "    def write(self, s):\n",
        "        super().write(s)\n",
        "        self.callback(s)\n",
        "\n",
        "\n",
        "@magics_class\n",
        "class ManimMagics(Magics):\n",
        "    path_line_start = 'File ready at '\n",
        "\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.defaults = {\n",
        "            'autoplay': True,\n",
        "            'controls': True,\n",
        "            'silent': True,\n",
        "            'width': 854,\n",
        "            'height': 480\n",
        "        }\n",
        "\n",
        "    video_settings = {'width', 'height', 'controls', 'autoplay'}\n",
        "    magic_off_switches = {\n",
        "        'verbose': 'silent',\n",
        "        'no-controls': 'controls',\n",
        "        'no-autoplay': 'autoplay'\n",
        "    }\n",
        "\n",
        "    @cell_magic\n",
        "    def manim(self, line, cell):\n",
        "        # execute the code - won't generate any video, however it will introduce\n",
        "        # the variables into the notebook's namespace (enabling autocompletion etc);\n",
        "        # this also allows users to get feedback on some code errors early on\n",
        "        get_ipython().ex(cell)\n",
        "        g_animator.arrange_nodes()\n",
        "        with open(\"tmpscript.json\", \"w\") as f:\n",
        "            json.dump(g_animator.plot_script, f, indent=2)\n",
        "\n",
        "        line = \"RendererMAnimV2 \" + line\n",
        "        user_args = line.split(' ')\n",
        "#         script_code = f\"\"\"import json\n",
        "# vscript = json.loads('''\"\"\" + \\\n",
        "# json.dumps(g_animator.plot_script, indent=2) + \"\"\"''')\n",
        "# \"\"\"\n",
        "#         print(\"**** line\")\n",
        "#         print(line)\n",
        "#         print(\"**** animation script\")\n",
        "#         print(script_code + _renderer_code)\n",
        "        \n",
        "        # path of the output video\n",
        "        path = None\n",
        "\n",
        "        settings = self.defaults.copy()\n",
        "\n",
        "        # disable the switches as indicated by the user\n",
        "        for key, arg in self.magic_off_switches.items():\n",
        "            if '--' + key in user_args:\n",
        "                user_args.remove('--' + key)\n",
        "                settings[arg] = False\n",
        "\n",
        "        resolution_index = (\n",
        "            user_args.index('-r') if '-r' in user_args else\n",
        "            user_args.index('--resolution') if '--resolution' in user_args else\n",
        "            None\n",
        "        )\n",
        "        if resolution_index is not None:\n",
        "            # the resolution is passed as \"height,width\"\n",
        "            try:\n",
        "                h, w = user_args[resolution_index + 1].split(',')\n",
        "                settings['height'] = h\n",
        "                settings['width'] = w\n",
        "            except (IndexError, KeyError):\n",
        "                warn('Unable to retrieve dimensions from your resolution setting, falling back to the defaults')\n",
        "\n",
        "        silent = settings['silent']\n",
        "\n",
        "        def catch_path_and_forward(lines):\n",
        "            nonlocal path\n",
        "            for line in lines.split('\\n'):\n",
        "                if not silent:\n",
        "                    print(line, file=std_out)\n",
        "\n",
        "                if line.startswith(self.path_line_start):\n",
        "                    path = line[len(self.path_line_start):].strip()\n",
        "\n",
        "        # Using a workaround for Windows permissions issue as in this questions:\n",
        "        # https://stackoverflow.com/q/15169101\n",
        "        #f = NamedTemporaryFile('w', suffix='.py', delete=False)\n",
        "        #\n",
        "\n",
        "        with open(\"tmprender.py\", \"w\") as f:\n",
        "            f.write(_renderer_code)\n",
        "\n",
        "    \n",
        "        try:\n",
        "            # f.write(cell)\n",
        "            # f.write(_renderer_code)\n",
        "            # f.close()\n",
        "            # args = ['manim', f.name, *user_args]\n",
        "            args = [\"manim\", \"tmprender.py\", *user_args]\n",
        "            \n",
        "\n",
        "            stdout = StringIOWithCallback(catch_path_and_forward)\n",
        "\n",
        "            with ExitStack() as stack:\n",
        "\n",
        "                enter = stack.enter_context\n",
        "\n",
        "                enter(patch.object(sys, 'argv', args))\n",
        "                enter(suppress(SystemExit))\n",
        "                enter(redirect_stdout(stdout))\n",
        "\n",
        "                if silent:\n",
        "                    stderr = StringIO()\n",
        "                    enter(redirect_stderr(stderr))\n",
        "\n",
        "                manimlib.main()\n",
        "        finally:\n",
        "            os.remove(f.name)\n",
        "\n",
        "        if path:\n",
        "            path = Path(path)\n",
        "            assert path.exists()\n",
        "\n",
        "            # To display a video in Jupyter, we need to have access to it\n",
        "            # so it has to be within the working tree. The absolute paths\n",
        "            # are usually outside of the accessible range.\n",
        "            relative_path = path.relative_to(Path.cwd())\n",
        "\n",
        "            video_settings = {\n",
        "                k: v\n",
        "                for k, v in settings.items()\n",
        "                if k in self.video_settings\n",
        "            }\n",
        "\n",
        "            return video(relative_path, **video_settings)\n",
        "        else:\n",
        "            just_show_help = '-h' in user_args or '--help' in user_args\n",
        "\n",
        "            if not just_show_help:\n",
        "                warn('Could not find path in the manim output')\n",
        "\n",
        "            # If we were silent, some errors could have been silenced too.\n",
        "            if silent:\n",
        "                # Let's break the silence:\n",
        "                print(stdout.getvalue())\n",
        "                print(stderr.getvalue(), file=sys.stderr)\n",
        "\n",
        "\n",
        "ip = get_ipython()\n",
        "ip.register_magics(ManimMagics)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mmv-O0uAP-Lt",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "########################################\n",
        "# Advanced logger\n",
        "import numpy as np\n",
        "class AnimatorSceneV2:\n",
        "    def __init__(self):\n",
        "        self.nodes = {}\n",
        "        self.edges = {}\n",
        "        self.x_alloc = 0\n",
        "        self.plot_script = []\n",
        "        \n",
        "    def make_animation_create(self, obj):\n",
        "        new_node = None\n",
        "        if isinstance(obj, NeuData):\n",
        "            from_id = None\n",
        "            depend_ord = 0\n",
        "            if obj.from_op is not None:\n",
        "                from_id = obj.from_op.id_\n",
        "                depend_ord = self.nodes[from_id]['depend_ord'] + 1\n",
        "            self.nodes[obj.id_] = dict(depend_ord=depend_ord)\n",
        "            self.plot_script.append(dict(\n",
        "                graph_object_type=\"DataNode\",\n",
        "                nodeid=obj.id_,\n",
        "                depend_ord=depend_ord,\n",
        "                from_ids=[from_id,],\n",
        "                text=obj.name,\n",
        "                data=obj.data,\n",
        "                animation_type=\"Create\"))\n",
        "        elif isinstance(obj, UnaryNeuOp):\n",
        "            oprand_key = obj.oprand.id_\n",
        "            oprand_node = self.nodes.get(oprand_key)\n",
        "            assert oprand_node is not None, \\\n",
        "                ValueError(\"Oprand node missing in animation\")\n",
        "            \n",
        "            # make node\n",
        "            depend_ord = oprand_node['depend_ord'] + 1\n",
        "            self.nodes[obj.id_] = dict(depend_ord=depend_ord)\n",
        "            self.plot_script.append(dict(\n",
        "                graph_object_type=\"OpNode\",\n",
        "                nodeid=obj.id_,\n",
        "                from_ids=[oprand_key,],\n",
        "                depend_ord=depend_ord,\n",
        "                text=obj.name,\n",
        "                animation_type=\"Create\"))\n",
        "            \n",
        "        elif isinstance(obj, BinaryNeuOp):\n",
        "            oprand_key1 = obj.oprand1.id_\n",
        "            oprand_node1 = self.nodes.get(oprand_key1)\n",
        "            assert oprand_node1 is not None, \\\n",
        "                ValueError(\"Oprand node missing in animation\")\n",
        "            oprand_key2 = obj.oprand2.id_\n",
        "            oprand_node2 = self.nodes.get(oprand_key2)\n",
        "            assert oprand_node2 is not None, \\\n",
        "                ValueError(\"Oprand node missing in animation\")\n",
        "            \n",
        "            # make node\n",
        "            depend_ord = max(oprand_node1['depend_ord'], oprand_node2['depend_ord']) + 1\n",
        "            self.nodes[obj.id_] = dict(depend_ord=depend_ord)\n",
        "            self.plot_script.append(dict(\n",
        "                graph_object_type=\"OpNode\",\n",
        "                nodeid=obj.id_,\n",
        "                from_ids=[oprand_key1, oprand_key2],\n",
        "                depend_ord=depend_ord,\n",
        "                text=obj.name,\n",
        "                animation_type=\"Create\"))\n",
        "            \n",
        "    def make_animation_forward(self, op_obj, resu):\n",
        "        if isinstance(op_obj, UnaryNeuOp):\n",
        "            oprand_key = op_obj.oprand.id_\n",
        "            oprand_node = self.nodes.get(oprand_key)\n",
        "            assert oprand_node is not None, \\\n",
        "                ValueError(\"Oprand nodes missing in animation\")\n",
        "            self.plot_script.append(dict(\n",
        "                graph_object_type=\"Message\",\n",
        "                from_ids=[oprand_key],\n",
        "                to_ids=[op_obj.id_],\n",
        "                depend_ord = self.nodes[op_obj.id_]['depend_ord'],\n",
        "                in_values=[op_obj.oprand.data],\n",
        "                out_values=[resu],\n",
        "                animation_type=\"Forward\"))\n",
        "            \n",
        "        elif isinstance(op_obj, BinaryNeuOp):\n",
        "            oprand1_key = op_obj.oprand1.id_\n",
        "            oprand2_key = op_obj.oprand2.id_\n",
        "            assert (self.nodes.get(oprand1_key) is not None) and\\\n",
        "                (self.nodes.get(oprand2_key) is not None), \\\n",
        "                ValueError(\"Oprand nodes missing in animation\")\n",
        "            self.plot_script.append(dict(\n",
        "                graph_object_type=\"Message\",\n",
        "                from_ids=[oprand1_key, oprand2_key],\n",
        "                to_ids=[op_obj.id_],\n",
        "                depend_ord = self.nodes[op_obj.id_]['depend_ord'],\n",
        "                in_values=[op_obj.oprand1.data, op_obj.oprand2.data],\n",
        "                out_values=[resu],\n",
        "                animation_type=\"Forward\"))\n",
        "            \n",
        "    def make_animation_backward(self, obj, msgs):\n",
        "        if isinstance(obj, NeuData):\n",
        "            self.plot_script.append(dict(\n",
        "                graph_object_type=\"GradNode\",\n",
        "                nodeid=obj.id_, # == msgs[0]['node_id']\n",
        "                depend_ord = self.nodes[obj.id_]['depend_ord'],\n",
        "                grad=msgs[0]['msg'],\n",
        "                animation_type=\"Create\"))\n",
        "        elif isinstance(obj, NeuOp):\n",
        "            self.plot_script.append(dict(\n",
        "                graph_object_type=\"GMessage\",\n",
        "                from_ids=[obj.id_,],\n",
        "                to_ids=[m['back_node_id'] for m in msgs],\n",
        "                depend_ord = self.nodes[obj.id_]['depend_ord'],\n",
        "                values=[m['msg'] for m in msgs],\n",
        "                animation_type=\"Backward\"))\n",
        "            \n",
        "    def arrange_nodes(self):\n",
        "        nodes = [_ for _ in self.plot_script\n",
        "            if _['graph_object_type'] in [\"DataNode\", \"OpNode\"]]\n",
        "        group_ids = [_[\"depend_ord\"] for _ in nodes]\n",
        "        group_num = np.unique(group_ids).size\n",
        "        \n",
        "        # adjust nodes dependency order: so to bring-forward some nodes \n",
        "        # close to where they are referred to\n",
        "        for nd in nodes:\n",
        "            nd_sub = [_ for _ in nodes if nd[\"nodeid\"] in _[\"from_ids\"]]\n",
        "            if len(nd_sub) > 0:\n",
        "                new_ord = max(nd[\"depend_ord\"], max([_[\"depend_ord\"]-1 for _ in nd_sub]))\n",
        "                if new_ord > nd[\"depend_ord\"]:\n",
        "                    print(f'{nd[\"nodeid\"]}:{nd[\"depend_ord\"]}->{new_ord}')\n",
        "                nd[\"depend_ord\"] = new_ord\n",
        "\n",
        "        # allocate screen areas for each group in computational dependency\n",
        "        x_ticks = np.linspace(0, 1, group_num+1)\n",
        "        group_areas = [dict(bottom=0, top=1, left=x0, right=x1) \n",
        "                       for x0, x1 in zip(x_ticks[:-1], x_ticks[1:])]\n",
        "\n",
        "        # in each area arrange the group members\n",
        "        for nd in nodes:\n",
        "            nd['sub_group'] = []\n",
        "        for gid, a in zip(reversed(sorted(np.unique(group_ids))), reversed(group_areas)):\n",
        "            group_nodes = [_ for _ in nodes if _[\"depend_ord\"] == gid]\n",
        "            y_locs = np.linspace(0, 1, len(group_nodes) + 2)[1:-1]\n",
        "\n",
        "            # sort nodes in a group according how they will be used to produce next group of nodes\n",
        "            for i, nd in enumerate(sorted(group_nodes,  \n",
        "                                          key=lambda nd:sum(nd['sub_group']) \\\n",
        "                                          / max(len(nd['sub_group']), 1e-6))):\n",
        "                # affect the order of nodes in proceeding group\n",
        "                for nd_ in nodes:\n",
        "                    if nd_['nodeid'] in nd['from_ids']:\n",
        "                        nd_['sub_group'].append(i)\n",
        "\n",
        "                # set up self position\n",
        "                nd['x'] = (a['left'] + a['right']) / 2\n",
        "                nd['y'] = y_locs[i]\n",
        "        return self.plot_script"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpVmM4E9MZmf",
        "colab_type": "text"
      },
      "source": [
        "### Libraries and Helpers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1Yfv7M2MhD0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as fn\n",
        "import PIL\n",
        "from PIL.Image import Image\n",
        "from torchvision.datasets import MNIST, CIFAR10\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "from torch.utils.data.dataset import Subset\n",
        "from torchvision.transforms import Compose, ToTensor, Normalize, ToPILImage\n",
        "from torch.optim import Adam, SGD\n",
        "mnist_dataset_trn = MNIST(root='./data', download=True, train=True,\n",
        "                          transform=ToTensor())\n",
        "mnist_dataset_tst = MNIST(root='./data', download=True, train=False,\n",
        "                          transform=ToTensor())\n",
        "mnist_train_loader = DataLoader(mnist_dataset_trn, batch_size=4)\n",
        "mnist_test_loader = DataLoader(mnist_dataset_tst, batch_size=4, shuffle=True)\n",
        "mnist_examples = mnist_dataset_trn[0]\n",
        "device = torch.device(\"cuda:0\") if torch.cuda.is_available \\\n",
        "    else torch.device(\"cpu\")\n",
        "\n",
        "def evaluate_model(model, tst_dataloader, max_iter=None):\n",
        "    total_corr = 0\n",
        "    total_num = 0\n",
        "    model.eval()\n",
        "    for i, (x, y) in enumerate(tst_dataloader):\n",
        "        with torch.no_grad():\n",
        "            pred_class_p = model(x.to(device))\n",
        "        corr_num = (torch.argmax(pred_class_p, dim=1).cpu() == y).sum()\n",
        "        total_corr += corr_num.item()\n",
        "        total_num += len(y)\n",
        "        if max_iter is not None:\n",
        "            if i >= max_iter:\n",
        "                break\n",
        "    accu = total_corr / total_num\n",
        "    return accu\n",
        "\n",
        "def simple_logger_factory(tst_dataloader=None):\n",
        "    def logger(model, info):\n",
        "        print(f\"Epoch {info['epoch']}, Iter {info['iter']}, \" +\n",
        "            f\"Train Loss {info['loss']}\")\n",
        "    def logger_eval(model, info):\n",
        "        test_accu = evaluate_model(model, tst_dataloader)\n",
        "        print(f\"Epoch {info['epoch']}, Iter {info['iter']}, \" +\n",
        "            f\"Train Loss {info['loss']} Test Accuracy {test_accu}\")\n",
        "    return logger if tst_dataloader is None else logger_eval\n",
        "\n",
        "simple_mnist_logger = simple_logger_factory(mnist_test_loader)\n",
        "    \n",
        "def train_model(model, trn_dataloader, start_iter=0,\n",
        "                max_iters=None, max_epoches=1, \n",
        "                trainer_class=Adam,\n",
        "                evaluate_every_n_iters=1000,\n",
        "                save_check_point_every_n_iters=10000,\n",
        "                evaluate_callback_fn=simple_logger_factory(),\n",
        "                **kwargs):\n",
        "    optim = trainer_class(model.parameters(), **kwargs)\n",
        "    model.train()\n",
        "    epoches = 0\n",
        "    iters = start_iter\n",
        "    running_loss = 0\n",
        "    while True:\n",
        "        for i, (x, y) in enumerate(trn_dataloader):\n",
        "            optim.zero_grad()\n",
        "            pred_class_p = model(x.to(device))\n",
        "            loss = fn.nll_loss(pred_class_p, y.to(device))\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "\n",
        "            iters += 1\n",
        "            running_loss += loss.item() \n",
        "            if iters % evaluate_every_n_iters == 0:\n",
        "                evaluate_callback_fn(\n",
        "                    model, dict(epoch=epoches, iter=iters, \n",
        "                                loss=running_loss / evaluate_every_n_iters))\n",
        "                running_loss = 0\n",
        "            if max_iters is not None and iters >= max_iters:\n",
        "                break\n",
        "\n",
        "        epoches += 1\n",
        "        if epoches >= max_epoches:\n",
        "            break\n",
        "        \n",
        "    return\n",
        "\n",
        "def count_param_num(model):\n",
        "    n = 0\n",
        "    for p in model.parameters():\n",
        "        n += p.numel()\n",
        "    return n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "io13HbPWKvX1",
        "colab_type": "text"
      },
      "source": [
        "## 2.1 Elements of Deep Neural Networks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuTdwf_pK2z-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Example of classifying hand-written digits.\n",
        "x, y = mnist_dataset_trn[42]\n",
        "print(f\"An example of digit {y}\")\n",
        "ToPILImage()(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03GP-XBAsqVi",
        "colab_type": "text"
      },
      "source": [
        "### 2.1.1 Shallow Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AiUvQ6lERzA4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A \"shallow\" network\n",
        "class Net1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net1, self).__init__()\n",
        "        self.lin1 = nn.Linear(in_features=28*28, out_features=64)\n",
        "        self.lin2 = nn.Linear(in_features=64, out_features=10)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        n = x.shape[0]\n",
        "        h = fn.relu(self.lin1(x.view(n, -1)))\n",
        "        y = fn.log_softmax(self.lin2(h), dim=1)\n",
        "        return y\n",
        "nn1 = Net1().to(device)\n",
        "train_model(nn1, mnist_train_loader, evaluate_callback_fn=simple_mnist_logger)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7shEN2Bts0Lj"
      },
      "source": [
        "### 2.1.2 Go Deeper"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AzEvgAmQs0Lm",
        "colab": {}
      },
      "source": [
        "# A naive deep network\n",
        "class NetD(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NetD, self).__init__()\n",
        "        self.lin1 = nn.Linear(in_features=28*28, out_features=64)\n",
        "        self.lin2 = nn.Linear(in_features=64, out_features=64)\n",
        "        self.lin3 = nn.Linear(in_features=64, out_features=64)\n",
        "        self.lin4 = nn.Linear(in_features=64, out_features=64)\n",
        "        self.lin5 = nn.Linear(in_features=64, out_features=10)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        n = x.shape[0]\n",
        "        h = fn.relu(self.lin1(x.view(n, -1)))\n",
        "        h = fn.relu(self.lin2(h))\n",
        "        h = fn.relu(self.lin3(h))\n",
        "        h = fn.relu(self.lin4(h))\n",
        "        h = self.lin5(h)\n",
        "        y = fn.log_softmax(h, dim=1)\n",
        "        return y\n",
        "dnn1 = NetD().to(device)\n",
        "train_model(dnn1, mnist_train_loader, evaluate_callback_fn=simple_mnist_logger)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "R83yfC35ujmN"
      },
      "source": [
        "### 2.1.3 Essentials: Convolutional Net"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWnQyXE7f5wu",
        "colab_type": "text"
      },
      "source": [
        "Paper: [link](http://vision.stanford.edu/cs598_spring07/papers/Lecun98.pdf); [link-2](http://yann.lecun.com/exdb/publis/pdf/lecun-99.pdf)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3oSIXeynujmQ",
        "colab": {}
      },
      "source": [
        "# A naive deep network\n",
        "class NetCD(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NetCD, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3)\n",
        "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3)\n",
        "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3)\n",
        "        self.lin4 = nn.Linear(in_features=32*3*3, out_features=64)\n",
        "        self.lin5 = nn.Linear(in_features=64, out_features=10)\n",
        "        \n",
        "    \n",
        "    def forward(self, x):\n",
        "        n = x.shape[0]\n",
        "        h = fn.max_pool2d(fn.relu(self.conv1(x)), kernel_size=2)\n",
        "        h = fn.max_pool2d(fn.relu(self.conv2(h)), kernel_size=2)\n",
        "        h = fn.relu(self.conv3(h)).view(n, -1)\n",
        "        h = fn.relu(self.lin4(h))\n",
        "        h = self.lin5(h)\n",
        "        y = fn.log_softmax(h, dim=1)\n",
        "        return y\n",
        "\n",
        "dnn2 = NetCD().to(device)\n",
        "train_model(dnn2, mnist_train_loader, evaluate_callback_fn=simple_mnist_logger)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyhrGOGkvzNb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "count_param_num(dnn2), count_param_num(dnn1), count_param_num(nn1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5oURQPW91Z9S"
      },
      "source": [
        "### 2.1.4 Essentials: Direct Link"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9u7gmeIgKsZ",
        "colab_type": "text"
      },
      "source": [
        "ResNet Paper: [link](https://arxiv.org/abs/1512.03385)\n",
        "\n",
        "Tutorial Video:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMzmK8qthEbx",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "from IPython.display import YouTubeVideo\n",
        "YouTubeVideo('XPpmzulEmjA', width=600, height=400)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "v0jKDtKY1Z9U",
        "colab": {}
      },
      "source": [
        "# A naive deep network\n",
        "class NetCDR(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NetCDR, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3)\n",
        "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3, padding=1)\n",
        "        self.lin4 = nn.Linear(in_features=576, out_features=64)\n",
        "        self.lin5 = nn.Linear(in_features=64, out_features=10)\n",
        "        \n",
        "    \n",
        "    def forward(self, x):\n",
        "        n = x.shape[0]\n",
        "        h = fn.max_pool2d(fn.relu(self.conv1(x)), kernel_size=2)\n",
        "        h = fn.max_pool2d(fn.relu(self.conv2(h)) + h , kernel_size=2)\n",
        "        h = (fn.relu(self.conv3(h)) + h).view(n, -1)\n",
        "        h = fn.relu(self.lin4(h))\n",
        "        h = self.lin5(h)\n",
        "        y = fn.log_softmax(h, dim=1)\n",
        "        return y\n",
        "\n",
        "dnn3 = NetCDR().to(device)\n",
        "train_model(dnn3, mnist_train_loader, evaluate_callback_fn=simple_mnist_logger)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "416FAJSM4szG"
      },
      "source": [
        "### 2.1.5 Essentials: Optimiser"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yuPwiKwcn7is"
      },
      "source": [
        "Adam Paper: [link](https://arxiv.org/abs/1412.6980)\n",
        "\n",
        "Overview tutorial: [link](http://ruder.io/optimizing-gradient-descent/)\n",
        "\n",
        "Tutorial Video:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "cellView": "both",
        "id": "31nds35un2i-",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "from IPython.display import YouTubeVideo\n",
        "YouTubeVideo('JXQT_vxqwIs', width=600, height=400)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2CYLhHBhETA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nn1a = Net1().to(device)\n",
        "train_model(nn1a, mnist_train_loader, evaluate_every_n_iters=100, \n",
        "            max_iters=2000,\n",
        "            trainer_class=Adam, lr=0.0001)\n",
        "\n",
        "nn1b = Net1().to(device)\n",
        "train_model(nn1b, mnist_train_loader, evaluate_every_n_iters=100, \n",
        "            max_iters=2000,\n",
        "            trainer_class=SGD, lr=0.0001) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vtkCPCzh85fz"
      },
      "source": [
        "### 2.1.6 Essentials: Mini-batches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bBK2elSe85f0",
        "colab": {}
      },
      "source": [
        "nn1a = Net1().to(device)\n",
        "mnist_train_loader128 = DataLoader(mnist_dataset_trn, batch_size=128)\n",
        "train_model(nn1a, mnist_train_loader128, evaluate_every_n_iters=10, \n",
        "            max_iters=100, trainer_class=Adam, lr=0.0001)\n",
        "\n",
        "nn1b = Net1().to(device)\n",
        "mnist_train_loader4 = DataLoader(mnist_dataset_trn, batch_size=4)\n",
        "train_model(nn1b, mnist_train_loader128, evaluate_every_n_iters=80, \n",
        "            max_iters=800, trainer_class=Adam, lr=0.0001)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kDcbA2g37nF2"
      },
      "source": [
        "### 2.1.7 Essentials: Batch Normalisation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qLwjySWKpFLs"
      },
      "source": [
        "BatchNorm Paper: [link](https://arxiv.org/abs/1502.03167)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_0ays4KH7nF5",
        "colab": {}
      },
      "source": [
        "# A naive deep network\n",
        "class NetCDRB(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NetCDRB, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3)\n",
        "        self.bn12 = nn.BatchNorm2d(16)\n",
        "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3, padding=1)\n",
        "        self.bn23 = nn.BatchNorm2d(16)\n",
        "        self.conv3 = nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3, padding=1)\n",
        "        self.bn34 = nn.BatchNorm2d(16)\n",
        "        self.lin4 = nn.Linear(in_features=576, out_features=64)\n",
        "        self.lin5 = nn.Linear(in_features=64, out_features=10)\n",
        "        \n",
        "    \n",
        "    def forward(self, x):\n",
        "        n = x.shape[0]\n",
        "        h = fn.max_pool2d(fn.relu(self.conv1(x)), kernel_size=2)\n",
        "        h = self.bn12(h)\n",
        "        h = fn.max_pool2d(fn.relu(self.conv2(h)) + h , kernel_size=2)\n",
        "        h = self.bn23(h)\n",
        "        h = self.bn34(fn.relu(self.conv3(h)) + h).view(n, -1)\n",
        "        h = fn.relu(self.lin4(h))\n",
        "        h = self.lin5(h)\n",
        "        y = fn.log_softmax(h, dim=1)\n",
        "        return y\n",
        "\n",
        "dnn4 = NetCDRB().to(device)\n",
        "train_model(dnn4, mnist_train_loader, evaluate_callback_fn=simple_mnist_logger)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "R4n7dCkr-dYo"
      },
      "source": [
        "### 2.1.7 Essentials: Regularisation by Dropout"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7hKjmPDpbDq",
        "colab_type": "text"
      },
      "source": [
        "Paper [link](http://jmlr.org/papers/volume15/srivastava14a.old/srivastava14a.pdf)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSg0JrYnpRWu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "from IPython.display import YouTubeVideo\n",
        "YouTubeVideo('vAVOY8frLlQ', width=600, height=400)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TilhLJYg-dYr",
        "colab": {}
      },
      "source": [
        "# A naive deep network\n",
        "class NetCDRD(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NetCDRD, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3)\n",
        "        self.dropout1 = nn.Dropout2d(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3, padding=1)\n",
        "        self.dropout2 = nn.Dropout2d(inplace=True)\n",
        "        self.conv3 = nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3, padding=1)\n",
        "        self.lin4 = nn.Linear(in_features=576, out_features=64)\n",
        "        self.lin5 = nn.Linear(in_features=64, out_features=10)\n",
        "        \n",
        "    \n",
        "    def forward(self, x):\n",
        "        n = x.shape[0]\n",
        "        h = fn.max_pool2d(fn.relu(self.conv1(x)), kernel_size=2)\n",
        "        h = self.dropout1(h)\n",
        "        h = fn.max_pool2d(fn.relu(self.conv2(h)) + h , kernel_size=2)\n",
        "        h = self.dropout2(h)\n",
        "        h = (fn.relu(self.conv3(h)) + h).view(n, -1)\n",
        "        h = fn.relu(self.lin4(h))\n",
        "        h = self.lin5(h)\n",
        "        y = fn.log_softmax(h, dim=1)\n",
        "        return y\n",
        "dnn5_dp = NetCDRD().to(device)\n",
        "\n",
        "small_train = Subset(mnist_dataset_trn, torch.arange(600))\n",
        "train_loader_sm = DataLoader(small_train, batch_size=4)\n",
        "train_model(dnn5_dp, train_loader_sm, evaluate_callback_fn=simple_mnist_logger,\n",
        "            evaluate_every_n_iters=150, max_epoches=10)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xCY-8YENMV3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dnn5_nodp = NetCDR().to(device)\n",
        "train_model(dnn5_nodp, train_loader_sm, evaluate_callback_fn=simple_mnist_logger,\n",
        "            evaluate_every_n_iters=150, max_epoches=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_evAuXycOwSr",
        "colab_type": "text"
      },
      "source": [
        "## 2.2 Automatic Differential Architecture Builder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80iOyHdoOwSv",
        "colab_type": "text"
      },
      "source": [
        "### 2.2.1 Managed variable and operator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nu-coCbnOwSw",
        "colab_type": "text"
      },
      "source": [
        "Modern architectures allow the user to  describe the computations in a data model (e.g. neural networks) naturally, and automatically configure necessary steps and the data structures for back propagation.  To be concrete, in the simple “processing step”:\n",
        "```\n",
        "Y = X1 + X2\n",
        "```\n",
        "The user has actually describe a relationship that “the value of a variable Y is the sum of the values of variables X1 and X2”.  Put it into details, \n",
        "> `Y`  is the result of an `operation of adding` two numbers\n",
        "\n",
        "> The `operation` takes its input 1 from `X1`;  takes its input 2 from `X2`\n",
        "\n",
        "Describing this seemingly simple process in details seems to be tautology. The advantage is that now it is possible to automatically construct the backpropagation chain to compute how the changes in the input X1 and X2 will affect the output Y. \n",
        "\n",
        "Let us represent the _variables_ and _operators_ we will use in _tractable_ computations. \n",
        "\n",
        "__Variables__: \n",
        "- _contain_ the following information:\n",
        "    - `data`: the content value\n",
        "    - `grad`: its effect on one target value, say, $\\frac{\\partial L}{\\partial x}$\n",
        "    - `from_op`: \"ancester\" of this piece of information, `None` or some operator. E.g. in $y = x_1 + x_2$, $x_1$ and $x_2$ have none ancester, $y$ is `from_op`erator \"+\".\n",
        "    - `id_`: and unique global ID\n",
        "- _perform_ the following functions:\n",
        "    - applying operator to `self` (and `another` `variable` object), see `__add__` function below.\n",
        "    - backpropating information of `grad` to the `from_op` (if it exists)\n",
        "\n",
        "__Operators__:\n",
        "- _contain_:\n",
        "    - a\n",
        "- _perform_ the following functions:\n",
        "    - applyi\n",
        "    \n",
        "    \n",
        "__EXERCISE__: Examine the operation of `Y = X1 + X2`\n",
        "\n",
        "__REMARK__\n",
        "You may think one target is too limited, but ..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "code_folding": [],
        "id": "iWYWrbN3OwSx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NeuData:\n",
        "    d_count = 0 # A class-wise *global* counter\n",
        "    \n",
        "    def __init__(self, data=0, grad=0, from_op=None, name=None):\n",
        "        # Essential information\n",
        "        # 1. the \"content\" of this variable\n",
        "        self.data = data \n",
        "        # 2. how this variable affects the \"total objective\"\n",
        "        # of a system. For machine learning problems, the\n",
        "        # system is determined by a global evaluation, often\n",
        "        # called a \"loss\"\n",
        "        self.grad = grad\n",
        "        # 3. the operation from which this variable has been computed\n",
        "        # if this variable is given (no computation is needed)\n",
        "        # this is None\n",
        "        self.from_op = from_op \n",
        "        \n",
        "        # Comp. Graph maintainance (and diagnosis and visualisation)\n",
        "        self.id_ = f\"D{NeuData.d_count}\"\n",
        "        NeuData.d_count += 1 # a global serial number\n",
        "\n",
        "        # Further information for diagnosis and visualisation\n",
        "        self.name = self.id_ if name is None else name\n",
        "        \n",
        "        # If configured, output log information\n",
        "        # Optionally, we can output some report at this point.\n",
        "        # E.g.\n",
        "        print(f\"Variable {self.name} has been created\" + \n",
        "              (\".\" if self.from_op is None else \n",
        "              f\" from the result of {self.from_op.name}\"))\n",
        "        \n",
        "    def __add__(self, another):\n",
        "        \"\"\"\n",
        "        This function builds a \"computational structure\" performing\n",
        "        ADDING between two Variables. \n",
        "        \n",
        "        The method __add__ will be called when the following piece\n",
        "        of code gets executed:\n",
        "            `variable_1 + variable_2`\n",
        "        then invocation would be\n",
        "            `variable_1.__add__(another=variable_2)` # self=variable_1\n",
        "            \n",
        "        To have the entire \"chain of information processing\" trackable, \n",
        "        we take the computation and management in our own hands:\n",
        "            1. create a *managed* operator to do the addition\n",
        "            2. create a new variable to contain the result -- do NOT\n",
        "              forget to tell the new variable where it comes from:\n",
        "              the operation we just created above.\n",
        "        \"\"\"\n",
        "        add_op = NeuOpAdd(self, another) # create an add-op, using self and \n",
        "            # another as its inputs.\n",
        "        return NeuData(add_op.forward(), from_op=add_op) # create a new \n",
        "            # variable, maintain the computation structure by \n",
        "            # - storing the value \n",
        "            #   - returned by the newly created op, which is \n",
        "            #   - which is commanded to perform its duty --\n",
        "            #   - adding input-1 and input-2; \n",
        "            # - establishing new var's dependency on the `from_op`\n",
        "            \n",
        "    def backward(self, g=1.0):\n",
        "        \"\"\"\n",
        "        This function creates a ring in the chain of back propagation.\n",
        "        When  informed that the change of my value will cause a change\n",
        "        in the final objective `L` by a certain amount `g`, the variable\n",
        "            1. accumulates `g` to `self.grad`, as one variable can have\n",
        "              multiple ways of affecting L, e.g. \n",
        "              L = X1 + Y; \n",
        "              Y = X1 + X2\n",
        "              Then a chenage X1 will affect L in two ways.\n",
        "            2. propagates the information to \n",
        "        \"\"\"\n",
        "        # accumulate grad\n",
        "        self.grad += g\n",
        "        # report\n",
        "        print(f\"{self.name} update grad: {self.grad-g:.3g} \"\n",
        "              f\"-> {self.grad:.3g}\")\n",
        "        # backprop grad\n",
        "        if self.from_op is not None:\n",
        "            self.from_op.backward(g)\n",
        "            \n",
        "            \n",
        "class NeuOpAdd:\n",
        "    op_count = 0 # global operator counter\n",
        "    \n",
        "    def __init__(self, oprand1, oprand2, name=None):\n",
        "        \"\"\"\n",
        "        Init of a PLUS operator, allocate an ID, ensure a name and\n",
        "        link the operator to the oprands.\n",
        "        \"\"\"\n",
        "        self.id_ = f\"Op+{NeuOpAdd.op_count}\"\n",
        "        NeuOpAdd.op_count += 1\n",
        "        self.name = self.id_ if name is None else name\n",
        "        # establish link to oprands\n",
        "        self.oprand1 = oprand1\n",
        "        self.oprand2 = oprand2\n",
        "        # report its creation\n",
        "        print(f\"Operator {self.name} has been created, getting inputs\"\n",
        "              f\" from {self.oprand1.name} and {self.oprand2.name}\")\n",
        "        \n",
        "    def forward(self):\n",
        "        \"\"\"\n",
        "        The computation. It is trivial for this operator.\n",
        "        \"\"\"\n",
        "        resu = self.oprand1.data + self.oprand2.data\n",
        "        # report\n",
        "        print(f\"{self.name} forwarding... \\n\"\n",
        "              f\"\\t input-1 {self.oprand1.name}: value {self.oprand1.data:.3g}\\n\"\n",
        "              f\"\\t input-2 {self.oprand2.name}: value {self.oprand2.data:.3g}\\n\"\n",
        "              f\"\\t ouput: {resu:.3g}\")\n",
        "        return resu      \n",
        "    \n",
        "    def backward(self, g):\n",
        "        \"\"\"\n",
        "        As a simple +, both inputs has equal effect on its output, i.e.\n",
        "        if the output of THIS + OPERATOR affects the global L by a factor \n",
        "        of g, so does the input-1 as well as input-2\n",
        "        \"\"\"\n",
        "        # backprop for op-1\n",
        "        op1_g = g\n",
        "        # report\n",
        "        print(f\"{self.name} transforming grad {g:.3g} to {op1_g:.3g}\"\n",
        "              f\" and pass to {self.oprand1.name}\")\n",
        "        self.oprand1.backward(op1_g)\n",
        "        \n",
        "        # backprop for op-2\n",
        "        op2_g = g\n",
        "        print(f\"{self.name} transforming grad {g:.3g} to {op2_g:.3g}\"\n",
        "              f\" and pass to {self.oprand2.name}\")\n",
        "        self.oprand2.backward(op2_g)\n",
        "        \n",
        "        \n",
        "              "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6U8XJ2UoOwSy",
        "colab_type": "text"
      },
      "source": [
        "__EXERCISE__\n",
        "\n",
        "Run the following code blocks and explain the outputs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZLZVBUMOwSy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x0 = NeuData(4, name=\"x0\")\n",
        "x1 = NeuData(3, name=\"x1\")\n",
        "L = x0 + x1\n",
        "print(\"================\\nComputation completed. \\n\"\n",
        "      f\"L name:{L.name}, id:{L.id_}, value:{L.data}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNTwYR3wOwSz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "L.backward()\n",
        "del x0, x1, L # explicitly remove those variables lest confusion"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoK8QI1IOwS1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x0 = NeuData(4, name=\"x0\")\n",
        "x1 = NeuData(3, name=\"x1\")\n",
        "x2 = NeuData(10, name=\"x2\")\n",
        "x3 = x0 + x1\n",
        "L = x3 + (x2 + x3)\n",
        "L.backward(1.0)\n",
        "del x0, x1, x2, x3, L"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmk-ebdTOwS3",
        "colab_type": "text"
      },
      "source": [
        "### 2.2.2 Full Version of Managed Variable/Op/Func/NeuralNets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwhgvkQ3OwS4",
        "colab_type": "text"
      },
      "source": [
        "We provide a primary but full-fledged computation framework of constructing NN models that can perform automatic backprop PROGRAMMING."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "code_folding": [
          2,
          36,
          53,
          70,
          83,
          103,
          124
        ],
        "id": "G_iz-McdOwS5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "########################################\n",
        "# Ops\n",
        "VERBOSE = True\n",
        "class NeuOp(object):\n",
        "    \"\"\"\n",
        "    Now we define a system of operators, this is the root class\n",
        "    defining the basic bookkeeping behaviour of operators.\n",
        "    \"\"\"\n",
        "    op_count = 0\n",
        "    \n",
        "    def __init__(self, name=None):\n",
        "        super(NeuOp, self).__init__()\n",
        "        self.id_ = f\"Op{NeuOp.op_count}\"\n",
        "        NeuOp.op_count += 1\n",
        "        if name is None:\n",
        "            name = self.id_\n",
        "        self.name = name\n",
        "    \n",
        "    def backward(self, g):\n",
        "        raise NotImplementedError\n",
        "        \n",
        "    def forward(self):\n",
        "        raise NotImplementedError\n",
        "        \n",
        "        \n",
        "    def make_animation_forward_(self, resu):\n",
        "        try:\n",
        "            g_animator.make_animation_forward(self, resu)\n",
        "        except Exception as e:\n",
        "            pass\n",
        "            \n",
        "    def make_animation_backward_(self, msgs):\n",
        "        try:\n",
        "            g_animator.make_animation_backward(self, msgs)\n",
        "        except Exception as e:\n",
        "            pass\n",
        "        \n",
        "class UnaryNeuOp(NeuOp):\n",
        "    \"\"\"\n",
        "    Operators who has only one oprand (input).\n",
        "    \"\"\"\n",
        "    def __init__(self, oprand, name=None):\n",
        "        super(UnaryNeuOp, self).__init__(name)\n",
        "        self.oprand = oprand\n",
        "        try:\n",
        "            g_animator.make_animation_create(self)\n",
        "        except:\n",
        "            pass\n",
        "        \n",
        "    def backward(self, g):\n",
        "        self.make_animation_backward_([\n",
        "            dict(back_node_id=self.oprand.id_, msg=g)])\n",
        "        self.oprand.backward(g)\n",
        "                \n",
        "class NeuOpNeg(UnaryNeuOp):\n",
        "    \"\"\"\n",
        "    Negation, the \"-\" operator.\n",
        "    \"\"\"\n",
        "    def __init__(self, oprand, name=\"-\"):\n",
        "        super(NeuOpNeg, self).__init__(oprand, name)\n",
        "    \n",
        "    def backward(self, g):\n",
        "        bg = -g\n",
        "        super(NeuOpNeg, self).backward(bg)\n",
        "\n",
        "        \n",
        "    def forward(self):\n",
        "        resu = -self.oprand.data\n",
        "        self.make_animation_forward_(resu)\n",
        "        return resu\n",
        "        \n",
        "class BinaryNeuOp(NeuOp):\n",
        "    \"\"\"\n",
        "    Binary Operators\n",
        "    \"\"\"\n",
        "    def __init__(self, oprand1, oprand2, name=None):\n",
        "        super(BinaryNeuOp, self).__init__(name)\n",
        "        self.oprand1 = oprand1\n",
        "        self.oprand2 = oprand2\n",
        "        try:\n",
        "            g_animator.make_animation_create(self)\n",
        "        except:\n",
        "            pass\n",
        "    \n",
        "class NeuOpAdd(BinaryNeuOp):\n",
        "    \"\"\"\n",
        "    Our old friend \"+\"\n",
        "    \"\"\"\n",
        "    def __init__(self, oprand1, oprand2, name=\"+\"):\n",
        "        super(NeuOpAdd, self).__init__(oprand1, oprand2, name)\n",
        "    \n",
        "    def backward(self, g):\n",
        "        self.make_animation_backward_([\n",
        "            dict(back_node_id=self.oprand1.id_, msg=g),\n",
        "            dict(back_node_id=self.oprand2.id_, msg=g)])\n",
        "        \n",
        "        self.oprand1.backward(g)\n",
        "        self.oprand2.backward(g)\n",
        "        \n",
        "    def forward(self):\n",
        "        resu = self.oprand1.data + self.oprand2.data\n",
        "        self.make_animation_forward_(resu)\n",
        "        return resu\n",
        "    \n",
        "class NeuOpMul(BinaryNeuOp):\n",
        "    \"\"\"* operator, note the backprop\"\"\"\n",
        "    def __init__(self, oprand1, oprand2, name=\"*\"):\n",
        "        super(NeuOpMul, self).__init__(oprand1, oprand2, name)\n",
        "    \n",
        "    def backward(self, g):\n",
        "        # output = in1 * in2, so dL/d_output * in2 = dL/d_in1, similarly for d_in2\n",
        "        self.make_animation_backward_([\n",
        "            dict(back_node_id=self.oprand1.id_, msg=g * self.oprand2.data),\n",
        "            dict(back_node_id=self.oprand2.id_, msg=g * self.oprand1.data)])\n",
        "        \n",
        "        self.oprand1.backward(g * self.oprand2.data)\n",
        "        self.oprand2.backward(g * self.oprand1.data)\n",
        "        \n",
        "    def forward(self):\n",
        "        resu = self.oprand1.data * self.oprand2.data\n",
        "        self.make_animation_forward_(resu)\n",
        "        return resu\n",
        "\n",
        "########################################\n",
        "# Data\n",
        "class NeuData:\n",
        "    d_count = 0\n",
        "    \n",
        "    def __init__(self, data=0, grad=None, from_op=None, name=None):\n",
        "        # essential information\n",
        "        self.data = data\n",
        "        self.grad = grad\n",
        "        self.from_op = from_op\n",
        "        \n",
        "        # comp. graph maintainance and visualisation\n",
        "        self.id_ = f\"D{NeuData.d_count}\"\n",
        "        NeuData.d_count += 1\n",
        "        if name is None:\n",
        "            name = self.id_\n",
        "        self.name = name\n",
        "                \n",
        "        try:\n",
        "            g_animator.make_animation_create(self)\n",
        "        except:\n",
        "            pass\n",
        "        \n",
        "    def __neg__(self):\n",
        "        neg_op = NeuOpNeg(self)\n",
        "        return NeuData(neg_op.forward(), from_op=neg_op)\n",
        "        \n",
        "    def __add__(self, another):\n",
        "        add_op = NeuOpAdd(self, another)\n",
        "        return NeuData(add_op.forward(), from_op=add_op)\n",
        "    \n",
        "    def __sub__(self, another):\n",
        "        add_op = NeuOpAdd(self, -another)\n",
        "        return NeuData(add_op.forward(), from_op=add_op)\n",
        "    \n",
        "    def __mul__(self, another):\n",
        "        mul_op = NeuOpMul(self, another)\n",
        "        return NeuData(mul_op.forward(), from_op=mul_op)\n",
        "    \n",
        "    def backward(self, g=1.0):\n",
        "        if self.grad is None:\n",
        "            self.grad = g\n",
        "        else:\n",
        "            self.grad += g\n",
        "            \n",
        "        if VERBOSE:\n",
        "            print(f\"{self.name} grad: {self.grad:.3f}\")\n",
        "        if self.from_op is not None:\n",
        "            self.from_op.backward(g)\n",
        "            \n",
        "    def __setattr__(self, name, value):\n",
        "        \n",
        "        if name == \"grad\" and value is not None:\n",
        "            try:\n",
        "                g_animator.make_animation_backward(\n",
        "                    self, \n",
        "                    [dict(node_id=self.id_, msg=value)])\n",
        "            except Exception as e:\n",
        "                pass\n",
        "        \n",
        "        super(NeuData, self).__setattr__(name, value)\n",
        "            \n",
        "        \n",
        "    def __str__(self):\n",
        "        return f\"{self.data}\"\n",
        "    \n",
        "    def __repr__(self):\n",
        "        return f\"{self.name}:{self.data:.3f}\" if self.grad is None \\\n",
        "            else f\"{self.name}:{self.data:.3f}:{self.grad:.3f}\"\n",
        "    \n",
        "########################################\n",
        "# Elementwise Functions\n",
        "import math\n",
        "class NeuFunction(object):\n",
        "    \"\"\"\n",
        "    Functions are customised Uniary operators.\n",
        "    The barrier for understanding is the dealing with backprop.\n",
        "    We create a unary op, and hack the object's back-prop function.\n",
        "    \"\"\"\n",
        "    def __init__(self, name=None):\n",
        "        super(NeuFunction, self).__init__()\n",
        "        self.name = name\n",
        "        \n",
        "    def forward(self, x):\n",
        "        import types\n",
        "        op = UnaryNeuOp(x, name=self.name)\n",
        "        # op will be our placeholder in the differentiable computational graph.\n",
        "        # we will never use op's forward computation (not defined anyway)\n",
        "        # but we will take advantage of the *automatic* invocation of op's\n",
        "        # `backward` method, which will be called when the output data pass\n",
        "        # gradient messages through. \n",
        "        \n",
        "\n",
        "        # We hijack the op's function and let it point to the `backward` function\n",
        "        # of THIS object. NOTE, not THIS CLASS, `self` here would represent an instance\n",
        "        # of a SUBCLASS, which will implement appropriate gradient transform.\n",
        "        # See the Sigmoid function example below.\n",
        "        op_original_back = op.backward\n",
        "        def _back(op_instance, g):\n",
        "            g_back = self.backward(op_instance, g) # self is subclass instance\n",
        "            op_original_back(g_back)\n",
        "        op.backward = types.MethodType(_back, op) # wrap it as a class-method function.\n",
        "            # see https://stackoverflow.com/questions/10374527/dynamically-assigning-function-implementation-in-python\n",
        "            # Amber's answer.\n",
        "        return op\n",
        "        \n",
        "    def backward(self, g):\n",
        "        raise NotImplementedError\n",
        "        \n",
        "    def __call__(self, x):\n",
        "        \"\"\"\n",
        "        This will make the object \"callable\", i.e.\n",
        "        f(x) === f.forward(x)\n",
        "        \"\"\"\n",
        "        return self.forward(x)\n",
        "\n",
        "def _sigmoid(x):\n",
        "    return 1 / (1 + math.exp(-x))\n",
        "\n",
        "class FuncSigmoid(NeuFunction):\n",
        "    def __init__(self, name=None):\n",
        "        super(FuncSigmoid, self).__init__(name)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        op = super(FuncSigmoid, self).forward(x)\n",
        "        resu = _sigmoid(x.data)\n",
        "        op.make_animation_forward_(resu)\n",
        "        out = NeuData(resu, from_op=op)\n",
        "        return out\n",
        "    \n",
        "    def backward(self, op, g):\n",
        "        x = op.oprand\n",
        "        y = _sigmoid(x.data)\n",
        "        g = g * y * (1 - y)\n",
        "        if VERBOSE:\n",
        "            print(f\"{self.name} pass-grad: {g:.3f}\")\n",
        "        return g\n",
        "\n",
        "########################################\n",
        "# Neural network components\n",
        "\n",
        "def flatten_data(dlist):\n",
        "    \"\"\"Yield items from any nested iterable; see Reference.\"\"\"\n",
        "    from collections.abc import Iterable\n",
        "    for x in dlist:\n",
        "        if isinstance(x, Iterable):\n",
        "            for sub_x in flatten_data(x):\n",
        "                yield sub_x\n",
        "        else:\n",
        "            assert isinstance(x, NeuData), ValueError(\"Must be neu data\")\n",
        "            yield x\n",
        "            \n",
        "class NeuParameterisedModule(object):\n",
        "    module_count = 0\n",
        "    def __init__(self, name=None):\n",
        "        if name is None:\n",
        "            name = f\"nn{NeuParameterisedModule.module_count}\"\n",
        "        self.name = name\n",
        "        NeuParameterisedModule.module_count += 1\n",
        "        self.parameters_ = []\n",
        "        \n",
        "    def __setattr__(self, name, value):\n",
        "        \"\"\"\n",
        "        We hack the setting attribute to do bookkeeping of learnable parameters:\n",
        "        \"\"\"\n",
        "        if name == \"parameters_\": # parameters are directly set\n",
        "            print(\"set param\")\n",
        "            value = list(flatten_data(value))\n",
        "            \n",
        "        if isinstance(value, NeuParameterisedModule): # member sub-modules added\n",
        "            print(\"add sub module\")\n",
        "            self.parameters_ += value.parameters_\n",
        "            \n",
        "        super(NeuParameterisedModule, self).__setattr__(name, value)\n",
        "    \n",
        "        \n",
        "    def forward(self, x):\n",
        "        raise NotImplementedError\n",
        "        \n",
        "    def __call__(self, x):\n",
        "        return self.forward(x)\n",
        "\n",
        "import random    \n",
        "class Linear(NeuParameterisedModule):\n",
        "    \"\"\"\n",
        "    Linear layer\n",
        "    \"\"\"\n",
        "    def __init__(self, in_features, out_features, name=None):\n",
        "        super(Linear, self).__init__(name)\n",
        "            \n",
        "        self.weights = \\\n",
        "            [[NeuData(random.gauss(0, 1), name=f\"{self.name}:w{_o,_i}\") \n",
        "              for _i in range(in_features)]\n",
        "             for _o in range(out_features)]\n",
        "        self.bias = \\\n",
        "            [NeuData(0, name=f\"{self.name}:b{_o}\") \n",
        "             for _o in range(out_features)]\n",
        "        \n",
        "        self.parameters_ = self.weights + self.bias\n",
        "        \n",
        "    def forward(self, x):\n",
        "        from functools import reduce\n",
        "        out = []\n",
        "        for w, b in zip(self.weights, self.bias):\n",
        "            weighted = [wj * xj for wj, xj in zip(w, x)]\n",
        "            out.append(reduce(lambda a1, a2:a1 + a2, weighted + [b,]))\n",
        "            \n",
        "        return out\n",
        "    \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbuRYY7gOwS6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Unit test of Functions\n",
        "f = FuncSigmoid()\n",
        "x1 = NeuData(0.2, name=\"x1\")\n",
        "w1 = NeuData(3, name=\"w1\")\n",
        "h = x1 * (w1 * w1)\n",
        "y = f(h) + f(w1)\n",
        "y.backward()\n",
        "print(f\"Auto-back w1.grad: {w1.grad}\")\n",
        "\n",
        "# Verify numerically\n",
        "f = lambda x: 1 / (1 + math.exp(-x))\n",
        "x1 = 0.2\n",
        "w1 = 3\n",
        "h = x1 * (w1 * w1)\n",
        "y = f(h) + f(w1)\n",
        "\n",
        "t_eps = 1e-3\n",
        "w1 += t_eps\n",
        "h = x1 * (w1 * w1)\n",
        "y_new = f(h) + f(w1)\n",
        "print(f\"Numerical w1.grad: {(y_new - y) / t_eps}\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQ5DMAxGOwS9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Test using our module to create a neural net\n",
        "class MyNN(NeuParameterisedModule):\n",
        "    def __init__(self, name=\"nn\"):\n",
        "        super(MyNN, self).__init__(name)\n",
        "        self.lin1 = Linear(in_features=2, out_features=3, name=f\"{self.name}:l1\")\n",
        "        self.lin2 = Linear(in_features=3, out_features=1, name=f\"{self.name}:l2\")\n",
        "        \n",
        "    def forward(self, x):\n",
        "        f = FuncSigmoid()\n",
        "        pre_h = self.lin1(x)\n",
        "        h = [ f(hi) for hi in pre_h ]\n",
        "        pre_out = self.lin2(h)\n",
        "        out = [ f(yi) for yi in pre_out ]\n",
        "        return out\n",
        "    \n",
        "random.seed(42)    \n",
        "mynn = MyNN()\n",
        "print(mynn.parameters_)\n",
        "y = mynn([NeuData(1), NeuData(2)])\n",
        "print(y[0])\n",
        "y[0].backward()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruuVtN0cvBCs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "g_animator = AnimatorSceneV2()\n",
        "x0 = NeuData(30, name=\"x0\")\n",
        "x1 = NeuData(5, name=\"x1\")\n",
        "w1 = NeuData(2, name=\"w1\")\n",
        "L = x0 + x1 * w1\n",
        "L.backward(1.0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJvCh16PvOOy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%manim -m\n",
        "print(\"Animation\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhA0aeIrVnTi",
        "colab_type": "text"
      },
      "source": [
        "## 2.3 Deep Architecture Applied"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RlJvHgkZ2V-",
        "colab_type": "text"
      },
      "source": [
        "### 2.3.1 Prepare Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srt1kTOiIjW8",
        "colab_type": "text"
      },
      "source": [
        "We copy the library, data and environment preparation below for quick and show reference."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXV1VixXV0a6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The example is adopted from pytorch document:\n",
        "# see https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#sphx-glr-beginner-blitz-cifar10-tutorial-py\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as fn\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Change the type of the virtual machine in \"Runtime/Runtime Type\"\n",
        "device = torch.device(\"cuda:0\") if torch.cuda.is_available() \\\n",
        "    else torch.device(\"cpu\")\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "\n",
        "\n",
        "# functions to show an image\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "\n",
        "# print labels\n",
        "print(' '.join(classes[l] for l in labels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WuGE_KsBZ66U",
        "colab_type": "text"
      },
      "source": [
        "### 2.3.2 Define and Train Network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZaYE4LnXG8A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.shape[0]\n",
        "        h = fn.max_pool2d(fn.relu(self.conv1(x)), kernel_size=2)\n",
        "        h = fn.max_pool2d(fn.relu(self.conv2(h)), kernel_size=2)\n",
        "        h = h.view(batch_size, -1)\n",
        "        h = fn.relu(self.fc1(h))\n",
        "        h = fn.relu(self.fc2(h))\n",
        "        y = self.fc3(h)\n",
        "        return y\n",
        "\n",
        "net = Net()\n",
        "net = net.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrSaT3mWXWji",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "for epoch in range(2):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = fn.cross_entropy(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 2000))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4r-4x4WljfM",
        "colab_type": "text"
      },
      "source": [
        "# 3 Generative Adversarial Nets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4v_YEjH_tHsi",
        "colab_type": "text"
      },
      "source": [
        "## 3.0 Helpers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "HxYFMQeztHsj",
        "colab_type": "text"
      },
      "source": [
        "### Env Prepare"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "ldbKXpIutHsk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import scipy.stats as ss\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "# Neural network preparation\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as fn\n",
        "import torch.optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "2v2uPcSrtHsn",
        "colab_type": "text"
      },
      "source": [
        "### Utilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "code_folding": [
          4,
          27
        ],
        "hidden": true,
        "id": "3Ojoiig4tHso",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_gmm_samples(sample_num, norm_params, \n",
        "                    weights=None, rng=None):\n",
        "    \"\"\"\n",
        "    Generate samples from a Gaussian distribution\n",
        "    \"\"\"\n",
        "    # take samples in two steps:\n",
        "    # 1. a stream of indices from which to choose the component\n",
        "    norm_params = np.atleast_2d(np.array(norm_params))\n",
        "    component_num = norm_params.shape[0]\n",
        "    if weights is None:\n",
        "        weights = np.ones(component_num) / component_num\n",
        "    if rng is None:\n",
        "        rng = np.random.RandomState(42)\n",
        "    component_num = norm_params.shape[0]\n",
        "    mixture_idx = rng.choice(component_num, size=sample_num, \n",
        "                             replace=True, p=weights)\n",
        "    # 2. sample the corresponding gaussian\n",
        "\n",
        "    x_samples = np.array([\n",
        "        (rng.randn() + norm_params[i][0]) * norm_params[i][1]\n",
        "        for i in mixture_idx])\n",
        "    return x_samples\n",
        "\n",
        "def get_gmm_pdf(norm_params, weights=None):\n",
        "    norm_params = np.atleast_2d(np.array(norm_params))\n",
        "    component_num = norm_params.shape[0]\n",
        "    if weights is None:\n",
        "        weights = np.ones(component_num) / component_num\n",
        "    \n",
        "    # define the PDF for mixture model.\n",
        "    def gmm_pdf(x):\n",
        "        p = np.zeros_like(x)\n",
        "        for (l, s), w in zip(norm_params, weights):\n",
        "            p += ss.norm.pdf(x, loc=l, scale=s) * w\n",
        "        return p\n",
        "            \n",
        "    min_val = (norm_params[:, 0] - 3 * norm_params[:, 1]).min()\n",
        "    max_val = (norm_params[:, 0] + 3 * norm_params[:, 1]).max()\n",
        "    x_grid = np.linspace(min_val, max_val, 200)\n",
        "    mixture_pdf_on_grid = gmm_pdf(x_grid)\n",
        "        \n",
        "    return gmm_pdf, x_grid, mixture_pdf_on_grid\n",
        "\n",
        "\n",
        "def get_gmm_logpdf_tensor(norm_params, weights=None):\n",
        "    norm_params = np.atleast_2d(np.array(norm_params))\n",
        "    component_num = norm_params.shape[0]\n",
        "    if weights is None:\n",
        "        weights = np.ones(component_num) / component_num\n",
        "        \n",
        "    norm_params_t = torch.Tensor(norm_params)\n",
        "    weights_t = torch.Tensor(weights)\n",
        "    \n",
        "    components = [torch.distributions.normal.Normal(l, s)\n",
        "                  for l, s in norm_params_t]\n",
        "    \n",
        "    \n",
        "    # define the PDF for mixture model.\n",
        "    def gmm_logpdf(x):\n",
        "        return torch.stack([\n",
        "            nd.log_prob(torch.Tensor(x)) * w\n",
        "            for nd, w in zip(components, weights_t)]).sum(dim=0)\n",
        "            \n",
        "    return gmm_logpdf\n",
        "       "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "ZUx-i01AtHsq",
        "colab_type": "text"
      },
      "source": [
        "### Visualiser Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "code_folding": [],
        "hidden": true,
        "id": "RxSt50V5tHsr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_xaxis(xx):\n",
        "    xaxis=go.layout.XAxis(\n",
        "            range=[xx.min(), xx.max()],\n",
        "            showgrid=False,\n",
        "            zeroline=False,\n",
        "            showline=True,\n",
        "            gridcolor='#bdbdbd',\n",
        "            gridwidth=1,\n",
        "            zerolinecolor='#969696',\n",
        "            zerolinewidth=2,\n",
        "            linecolor='#636363',\n",
        "            linewidth=2,\n",
        "            mirror=True,\n",
        "            showspikes=True\n",
        "        )\n",
        "    return xaxis\n",
        "\n",
        "\n",
        "def get_yaxis(max_y):\n",
        "    yaxis=go.layout.YAxis(\n",
        "            range=[0, max_y],\n",
        "            title=\"Probability\",\n",
        "            showgrid=False,\n",
        "            zeroline=False,\n",
        "            showline=True,\n",
        "            gridcolor='#bdbdbd',\n",
        "            gridwidth=1,\n",
        "            linecolor='#636363',\n",
        "            linewidth=2,\n",
        "            mirror=True,\n",
        "        )\n",
        "    return yaxis\n",
        "\n",
        "\n",
        "\n",
        "def get_layout(xx, max_y=1.0):\n",
        "    layout = go.Layout(\n",
        "        hovermode=\"closest\",\n",
        "        xaxis=get_xaxis(xx),\n",
        "        yaxis=get_yaxis(max_y),\n",
        "        yaxis2=go.layout.YAxis(\n",
        "            range=[0, 10],\n",
        "            title=\"Samples\",\n",
        "            titlefont=dict(color=\"#ff7f0e\"),\n",
        "            tickfont=dict(color=\"#ff7f0e\"),\n",
        "            anchor=\"free\",\n",
        "            overlaying=\"y\",\n",
        "            side=\"right\",\n",
        "            position=1.00\n",
        "        ),\n",
        "        height=400,\n",
        "        width=600,)\n",
        "    return layout\n",
        "\n",
        "def get_training_frames(x, preds, color=\"red\"):\n",
        "    \n",
        "    frames=[go.Frame(\n",
        "        data=[go.Scatter(\n",
        "            x=x,\n",
        "            y=y,\n",
        "            mode=\"markers\",\n",
        "            marker=dict(\n",
        "            line_width=1,\n",
        "            color=color,\n",
        "            opacity=0.8))])\n",
        "        for y in preds]\n",
        "    return frames\n",
        "    \n",
        "\n",
        "def visualise_pdf(x_values, prob_values=None, show_pdf_text=False, show=True,\n",
        "    color=\"blue\", fill=True, name=\"PDF\", fig=None,\n",
        "                 samples=None):\n",
        "    if show_pdf_text:\n",
        "        pdf_text = [f\"Prob(x={x:.2f}) = {y:.2f}\"\n",
        "                    for x, y in zip(x_values, prob_values)]\n",
        "        pdf_hoverinfo = \"text\"\n",
        "    else:\n",
        "        pdf_text = \"\"\n",
        "        pdf_hoverinfo = \"none\"\n",
        "    fig_data = []\n",
        "    \n",
        "    if prob_values is not None:\n",
        "        pdf_scatter = go.Scatter(\n",
        "            x=x_values, y=prob_values, \n",
        "            marker=dict(\n",
        "                line_width=1,\n",
        "                color=color,\n",
        "                colorscale=\"Cividis\",\n",
        "                symbol=\"square\",\n",
        "                opacity=0.5\n",
        "            ),\n",
        "            mode=\"lines\",\n",
        "            fill=\"tozeroy\" if fill else \"none\",\n",
        "            name=name,\n",
        "            text=pdf_text,\n",
        "            hoverinfo=pdf_hoverinfo)\n",
        "        new_y_max = np.max(prob_values) * 1.05\n",
        "        fig_data.append(pdf_scatter)\n",
        "    else:\n",
        "        new_y_max = None\n",
        "\n",
        "    \n",
        "    \n",
        "    if samples is not None:\n",
        "        sample_histogram = go.Histogram(\n",
        "            x=samples, \n",
        "            xbins=dict(start=x_values.min(), \n",
        "                       end=x_values.max(), \n",
        "                       size=0.1),\n",
        "            yaxis=\"y2\", \n",
        "            opacity=0.8,\n",
        "            marker=dict(color=\"orange\"),\n",
        "            name=\"Samples\")\n",
        "        \n",
        "        fig_data.append(sample_histogram)\n",
        "    \n",
        "    if fig is None:\n",
        "        layout = get_layout(x_grid, np.max(prob_values) * 1.05)\n",
        "        fig = go.Figure(\n",
        "                data=fig_data,\n",
        "                layout=layout,\n",
        "                layout_title_text=\"Probabilistic Density\",\n",
        "            )\n",
        "    else:\n",
        "        for tr_ in fig_data:\n",
        "            fig.add_trace(tr_)\n",
        "        if new_y_max is not None:\n",
        "            orig_y_max = fig.layout.yaxis.range[1]\n",
        "            fig.update_layout({\"yaxis\":{\"range\":[0, max(new_y_max, orig_y_max)]}})\n",
        "        \n",
        "    if show:\n",
        "        fig.show()\n",
        "    return fig\n",
        "\n",
        "        \n",
        "def ___samples(\n",
        "    norm_params,\n",
        "    weights=None,\n",
        "    bootstrap_times_to_display=3,\n",
        "    show_sample=False,\n",
        "    estimator=np.median,\n",
        "    rng=None,\n",
        "    sample_num=None):\n",
        "    pdf, x_grid, mixture_pdf = get_gmm_pdf(norm_params, weights)\n",
        "   \n",
        "    if show_sample:\n",
        "        x_samples = get_gmm_samples(sample_num, norm_params, rng)\n",
        "        sample_histogram = go.Histogram(\n",
        "            x=x_samples, \n",
        "            xbins=dict(start=min_val, end=max_val, size=0.05),\n",
        "            yaxis=\"y2\", \n",
        "            opacity=0.8,\n",
        "            marker=dict(color=\"orange\"),\n",
        "            name=\"Samples\")\n",
        "        \n",
        "        fig_data.append(sample_histogram)\n",
        "            \n",
        "\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04p2-T_StHss",
        "colab_type": "text"
      },
      "source": [
        "## 3.1 Generative Model Basics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBuREKX2lUDb",
        "colab_type": "text"
      },
      "source": [
        "What are GAN models? What the tutorial video below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-tN2x4wkJLV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@GAN Introduction\n",
        "from IPython.display import YouTubeVideo\n",
        "YouTubeVideo('PhCM3qoRZHE', width=600, height=400)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "_4wsU1KXtHst",
        "colab_type": "text"
      },
      "source": [
        "### 3.1.1 To Model Data by Approximating the PDF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "gu_Zr8FHtHst",
        "colab_type": "text"
      },
      "source": [
        "To begin with, let us have a data distribution. A distribution is fully characterised by the _probility density function_.\n",
        "\n",
        "Check the pdf below. We will use this function as our running example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "run_control": {
          "marked": false
        },
        "id": "WlLMkQeCtHsu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ex_gmm_parameters = [[0, 1], [3, 0.5]]\n",
        "pdf_fn, x_grid, _ = get_gmm_pdf(ex_gmm_parameters)\n",
        "pdf_values = pdf_fn(x_grid)\n",
        "fig = visualise_pdf(x_grid, pdf_values, show=True, show_pdf_text=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "ImCc9ymMtHsw",
        "colab_type": "text"
      },
      "source": [
        "Then we create a model for the distribution. Let's use a neural network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "EtdnbAEItHsw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PDFNet1D(nn.Module):\n",
        "    def __init__(self, hidden_units=2):\n",
        "        super(PDFNet1D, self).__init__()\n",
        "        self.lin1 = nn.Linear(in_features=1, out_features=hidden_units)\n",
        "        self.lin2 = nn.Linear(in_features=hidden_units, out_features=1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        h = torch.tanh(self.lin1(x)) \n",
        "        p = torch.sigmoid(self.lin2(h)) # as PDF only takes positive values\n",
        "        return p\n",
        "\n",
        "class NumpyWrapper:\n",
        "    def __init__(self, net):\n",
        "        self.net = net\n",
        "    \n",
        "    def __call__(self, x):\n",
        "        x_in = np.atleast_2d(x).T if x.ndim < 2 else x\n",
        "            \n",
        "        with torch.no_grad():\n",
        "            y = self.net(torch.Tensor(x_in)).cpu().numpy()\n",
        "        return y.reshape(x.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "run_control": {
          "marked": false
        },
        "id": "6w3dInLWtHsx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.manual_seed(42)\n",
        "pdf_net_ = PDFNet1D()\n",
        "pdf_approx = NumpyWrapper(pdf_net_)\n",
        "# x_grid is the range of x values, created by the \"true\" pdf builder\n",
        "fig2 = visualise_pdf(x_grid, pdf_approx(x_grid), show=True, show_pdf_text=True, fig=fig,\n",
        "                     name=\"Approx\", color=\"red\", fill=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "lxuSTzuntHsy",
        "colab_type": "text"
      },
      "source": [
        "So we notice our function is not fitting so well with the true PDF. Let's do a bit training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "NC4iMt2AtHsz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.optim import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "cmap=plt.cm.get_cmap('Blues')\n",
        "\n",
        "NEURON_NUM = 20\n",
        "MAX_TRAIN = 10000\n",
        "EVERY_REPORT = 2000\n",
        "\n",
        "# Define a net\n",
        "torch.manual_seed(42)\n",
        "pdf_net_ = PDFNet1D(NEURON_NUM)\n",
        "pdf_approx = NumpyWrapper(pdf_net_)\n",
        "fig = visualise_pdf(x_grid, pdf_fn(x_grid), show=False, show_pdf_text=True)\n",
        "\n",
        "# Perform Training\n",
        "optim = Adam(pdf_net_.parameters())\n",
        "x_trn = torch.Tensor(x_grid[:, np.newaxis])\n",
        "y_trn = torch.Tensor(pdf_fn(x_grid)[:, np.newaxis])\n",
        "print(pdf_net_(x_trn).shape)\n",
        "\n",
        "preds = []\n",
        "for i in range(MAX_TRAIN):\n",
        "    optim.zero_grad()\n",
        "    pred = pdf_net_(x_trn)\n",
        "    loss = fn.mse_loss(pred, y_trn)\n",
        "    loss.backward()\n",
        "    optim.step()\n",
        "    if i % EVERY_REPORT == 0: \n",
        "        print(loss.item())\n",
        "        preds.append(pred.detach().cpu().numpy().squeeze())\n",
        "\n",
        "        fig = visualise_pdf(x_grid, pdf_approx(x_grid), show=False, show_pdf_text=True, \n",
        "                             fig=fig,\n",
        "                             name=f\"Approx @ {i}\", \n",
        "                             color=cmap(i/EVERY_REPORT), fill=False)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "OiWcFtJAtHs0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig.show() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogNi_SkVtHs0",
        "colab_type": "text"
      },
      "source": [
        "### 3.1.2 Generative Model "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S25OHqnvtHs1",
        "colab_type": "text"
      },
      "source": [
        "It seems that we can achieve learning a PDF in such a simple way. There are two issues:\n",
        "\n",
        "1. The loss is computed over the entire data space, so we must scan entire data space, which is not practically feasilbe.\n",
        "2. After training, the model can tell if an X belongs to the data, which is not entirely useful if explicit generation is needed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7j2ZGru1tHs1",
        "colab_type": "text"
      },
      "source": [
        "#### Generator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-AQlxyqdtHs1",
        "colab_type": "text"
      },
      "source": [
        "We adopt the idea of a generator: it takes a _random number_ as input, and produces a data sample."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHxF173ttHs1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, hidden_units=4):\n",
        "        super(Generator, self).__init__()\n",
        "        self.lin1 = nn.Linear(in_features=1, out_features=hidden_units)\n",
        "        self.bn1 = nn.BatchNorm1d(hidden_units)\n",
        "        self.lin2 = nn.Linear(in_features=hidden_units, \n",
        "                              out_features=hidden_units)\n",
        "        self.bn2 = nn.BatchNorm1d(hidden_units)\n",
        "        self.lin3 = nn.Linear(in_features=hidden_units, out_features=1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        h = self.bn1(torch.tanh(self.lin1(x)))\n",
        "        h = self.bn2(torch.tanh(self.lin2(h)))\n",
        "        out = self.lin3(h)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RChv3gN8tHs2",
        "colab_type": "text"
      },
      "source": [
        "The idea is to model the _transform_ from a uniform box into the true data distribution. Let's see an example. The `model_g` tries to map $[0, 1]$ to the distribution represented by our PDF."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzAPT96QtHs2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "to_numpy_1d = lambda x:x.detach().cpu().numpy().squeeze()\n",
        "torch.manual_seed(42)\n",
        "model_g = Generator(16)\n",
        "random_input = torch.rand(100, 1)\n",
        "fake_x = model_g(random_input)\n",
        "fake_x_np = to_numpy_1d(fake_x)\n",
        "\n",
        "# Visualise the samples\n",
        "fig = visualise_pdf(x_grid, pdf_fn(x_grid), samples=fake_x_np)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYLbhF28tHs3",
        "colab_type": "text"
      },
      "source": [
        "#### Naive Improvement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j36RdwHWtHs3",
        "colab_type": "text"
      },
      "source": [
        "Apparently this is not very successful.  so now let's consider how to improve it.   A natural idea is to adjust the parameters in the generator network so that the “fake-x” it generates has a higher probability according to the PDF function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Rtpd6ELtHs4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# NOTE: If you want to start from scratch, e.g. to reset the\n",
        "# visualisation figure. Re-run the cell above.\n",
        "\n",
        "MAX_TRAIN = 10000\n",
        "EVERY_REPORT = 2000\n",
        "\n",
        "# We need a pdf that handles tensor data.\n",
        "logpdf_fn_t = get_gmm_logpdf_tensor(ex_gmm_parameters)\n",
        "\n",
        "# Allocate an optimiser for model_g\n",
        "optim_g = Adam(model_g.parameters(), lr=1e-4)\n",
        "\n",
        "fig = visualise_pdf(x_grid, pdf_fn(x_grid), show=False)\n",
        "for i in range(MAX_TRAIN):\n",
        "    optim_g.zero_grad()\n",
        "    # take a new set of random inputs\n",
        "    random_input = torch.rand(100, 1)\n",
        "    # map random to the fake x\n",
        "    fake_x = model_g(random_input)\n",
        "    # evaluate the current fake x w.r.t. PDF\n",
        "    fake_prob = logpdf_fn_t(fake_x.squeeze())\n",
        "    # we want the fake_prob as large as possible\n",
        "    # so negate the sum as loss\n",
        "    loss = - fake_prob.mean()\n",
        "    loss.backward()\n",
        "    optim_g.step()\n",
        "    if i % EVERY_REPORT == 0: \n",
        "        print(loss.item())\n",
        "\n",
        "        fig = visualise_pdf(x_grid, show=False, \n",
        "                            fig=fig,\n",
        "                            name=f\"Samples @ {i}\", \n",
        "                            color=cmap(i/EVERY_REPORT), \n",
        "                            samples=to_numpy_1d(fake_x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gbUBmEWtHs5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8jFF-tVtHs5",
        "colab_type": "text"
      },
      "source": [
        "#### Discriminator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67aQWFTItHs6",
        "colab_type": "text"
      },
      "source": [
        "There is an obvious problem in the above solution:\n",
        "\n",
        "> The high-probability strategy drives the generator to push all the samples into the area with highest probability density,  which makes sense only from a local view. Globally the samples generated are very different from the true population of the data.\n",
        "\n",
        "A natural solution is to introduce our counter mechanism,  we do not want the samples produced by the generator to be easily distinguished from the true population.\n",
        "\n",
        "To put it formally, the current problem is that, when the \"counterfeiter\" puts all effort in optimising the $p(x)$ it generates, we will have different\n",
        "$p(x|TrueData)$ and $p(x|FakeData)$. The formal way of stating \"true and false data are easily distinguished\" is that the _posterior probabilities_\n",
        "$$\n",
        "p(\\{True,Fake\\}|x)\n",
        "$$\n",
        "are different.\n",
        "\n",
        "So in the next step we will try to make the posteriors similar."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAy2JwQktHs6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data management\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.data.sampler import WeightedRandomSampler\n",
        "\n",
        "class FakeSampleInXSpaceDataset(Dataset):\n",
        "    \"\"\"Face Landmarks dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, fake_samples, x_values):\n",
        "        \"\"\"\n",
        "        :param fake_samples: samples for which the probability is to be modelled\n",
        "        :param x_values: non-sample common x\n",
        "        \"\"\"\n",
        "        self.x_samples_ = torch.cat((fake_samples, x_values))\n",
        "        self.y_samples_ = torch.cat((torch.ones_like(fake_samples), \n",
        "                                    torch.zeros_like(x_values)))\n",
        "            # as training data, we would like the model fit to this data\n",
        "            # to generate 1.0 for fake samples and 0.0 for normal x-values\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.landmarks_frame)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        sample = self.x_samples_[idx], self.y_samples_[idx]\n",
        "\n",
        "        return sample\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9O_TdiuOtHs7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fake data density estimator\n",
        "\n",
        "class FakeDensityEstimator(nn.Module):\n",
        "    \"\"\"\n",
        "    Input X, Output Prob(x) According to Fake Data Population\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, hidden_units=4):\n",
        "        super(FakeDensityEstimator, self).__init__()\n",
        "        self.lin1 = nn.Linear(in_features=1, out_features=hidden_units)\n",
        "        #self.bn1 = nn.BatchNorm1d(hidden_units)\n",
        "        self.lin2 = nn.Linear(in_features=hidden_units, \n",
        "                              out_features=hidden_units)\n",
        "        self.lin3 = nn.Linear(in_features=hidden_units, out_features=1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        h = torch.tanh(self.lin1(x)) # h = self.bn1(h)\n",
        "        h = torch.tanh(self.lin2(h))\n",
        "        out = self.lin3(h)\n",
        "        return out\n",
        "    \n",
        "\n",
        "\n",
        "def fit_fake_density(fake_density_model, fake_samples, x_values,\n",
        "                     max_iter=1000):\n",
        "    fake_samples = torch.Tensor(fake_samples).squeeze()\n",
        "    x_values = torch.Tensor(x_values).squeeze()\n",
        "    optim = Adam(fake_density_model.parameters(), lr=1e-4)\n",
        "    train_dataset = FakeSampleInXSpaceDataset(fake_samples, x_values)\n",
        "    samples_weight = torch.cat((\n",
        "        torch.ones_like(fake_samples) / len(fake_samples) / 2,\n",
        "        torch.ones_like(x_values) / len(x_values) / 2,))\n",
        "    sampler = WeightedRandomSampler(samples_weight, len(samples_weight),\n",
        "                                   replacement=True)\n",
        "    data_loader = DataLoader(train_dataset, batch_size=16,\n",
        "                            sampler=sampler)\n",
        "    it = 0\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    while it < max_iter:\n",
        "        # take random samples from fake_samples and x_values respectively\n",
        "        for x, y in data_loader:\n",
        "            optim.zero_grad()\n",
        "            pred = fake_density_model(x.unsqueeze(dim=1))\n",
        "            loss =  criterion(pred.squeeze(), y) #- (pred * y).mean()\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "            \n",
        "        if it % (max_iter / 5) == 0:\n",
        "            print(\"Fake PDF Fitting Loss\", loss.item())\n",
        "        it += 1\n",
        "\n",
        "        \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jr5kae_ItHs8",
        "colab_type": "text"
      },
      "source": [
        "Let's test how the fake density estimator fits to the fake samples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0-5YrQHtHs8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "# Let us re-train the generator G, then Fit our PDF to G\n",
        "\n",
        "# 0. Define G\n",
        "model_g = Generator(16)\n",
        "random_input = torch.rand(100, 1)\n",
        "fake_x = model_g(random_input)\n",
        "\n",
        "# 1. Train G for a while\n",
        "MAX_TRAIN_GEN = 10\n",
        "EVERY_REPORT_GEN = 5\n",
        "\n",
        "# We need a pdf that handles tensor data.\n",
        "logpdf_fn_t = get_gmm_logpdf_tensor(ex_gmm_parameters)\n",
        "\n",
        "# Allocate an optimiser for model_g\n",
        "optim_g = Adam(model_g.parameters(), lr=1e-4)\n",
        "\n",
        "\n",
        "for i in range(MAX_TRAIN_GEN):\n",
        "    optim_g.zero_grad()\n",
        "    random_input = torch.rand(100, 1)\n",
        "    fake_x = model_g(random_input)\n",
        "    fake_prob = logpdf_fn_t(fake_x.squeeze())\n",
        "    loss = - fake_prob.mean()\n",
        "    loss.backward()\n",
        "    optim_g.step()\n",
        "    if i % EVERY_REPORT_GEN == 0: \n",
        "        print(\"G Loss\", loss.item())\n",
        "\n",
        "# 2. Fit a PDF to this G-generated samples\n",
        "random_input = torch.rand(200, 1)\n",
        "fake_x = model_g(random_input).detach()\n",
        "\n",
        "fake_density_model = FakeDensityEstimator(16)\n",
        "fit_fake_density(fake_density_model, fake_x.squeeze(), x_grid, max_iter=300)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeTlc6BVtHs9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fake_density_pdf = fn.sigmoid(\n",
        "    fake_density_model(torch.Tensor(x_grid).unsqueeze(1)))\n",
        "\n",
        "fig = visualise_pdf(x_grid, to_numpy_1d(fake_density_pdf), \n",
        "                    samples=to_numpy_1d(fake_x),\n",
        "                    name=\"PDF Fake, Estimated\",\n",
        "                    color=\"#646432\",\n",
        "                    show=False)\n",
        "fig = visualise_pdf(x_grid, pdf_values, \n",
        "                    name=\"PDF True\",\n",
        "                    fig=fig,\n",
        "                    show=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q60I8p-VtHs-",
        "colab_type": "text"
      },
      "source": [
        "#### Breakthrough: Use Discriminator to supervise generator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6kV9NyjtHs-",
        "colab_type": "text"
      },
      "source": [
        "Now, let us adopt the important idea, the models $X_{Fake}$ a generator produces should make the probability density estimated from $X_{Fake}$ very similar to the original density. So here we will have a GAME:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xG5-hZDTtHs-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "# Let us re-train the generator G, then Fit our PDF to G\n",
        "\n",
        "# 0. Define G and Fake density estimator\n",
        "model_g = Generator(16)\n",
        "fake_density_model = FakeDensityEstimator(16)\n",
        "# We need a pdf that handles tensor data.\n",
        "logpdf_fn_t = get_gmm_logpdf_tensor(ex_gmm_parameters)\n",
        "# Allocate an optimiser for model_g\n",
        "optim_g = Adam(model_g.parameters(), lr=1e-4)\n",
        "\n",
        "MAX_GAMES = 100\n",
        "EVERY_REPORT_GAME = 20\n",
        "MAX_TRAIN_GEN = 10\n",
        "EVERY_REPORT_GEN = 5\n",
        "MAX_ADJUST_ITERS = 5\n",
        "\n",
        "\n",
        "#### GAME STARTS ####\n",
        "game = 0\n",
        "while game < MAX_GAMES:\n",
        "    # 1. Train G for a while\n",
        "    for i in range(MAX_TRAIN_GEN):\n",
        "        optim_g.zero_grad()\n",
        "        random_input = torch.rand(100, 1)\n",
        "        fake_x = model_g(random_input)\n",
        "        fake_prob = logpdf_fn_t(fake_x.squeeze())\n",
        "        loss = - fake_prob.mean()\n",
        "        loss.backward()\n",
        "        optim_g.step()\n",
        "        if i % EVERY_REPORT_GEN == 0: \n",
        "            print(\"G Loss\", loss.item())\n",
        "\n",
        "    # 2. Fit a PDF to this G-generated samples\n",
        "    random_input = torch.rand(200, 1)\n",
        "    fake_x = model_g(random_input).detach()\n",
        "    fit_fake_density(fake_density_model, fake_x.squeeze(), \n",
        "                     x_grid, max_iter=100)\n",
        "    \n",
        "    # 3. !! NEW !!\n",
        "    # Use G to map another group of random numbers for some fake samples\n",
        "    # Let Density estimator to check how likely those fake samples belong\n",
        "    # to G-induced distribution versus the original distribution.\n",
        "    for i in range(MAX_ADJUST_ITERS):\n",
        "        random_input = torch.rand(200, 1)\n",
        "        fake_x = model_g(random_input) # No detach! as we will use the info to \n",
        "            # adjust parameters in G.\n",
        "        gen_sample_fake_likelihood = fake_density_model(fake_x).squeeze()\n",
        "        gen_sample_true_likelihood = logpdf_fn_t(fake_x).squeeze()\n",
        "\n",
        "        # The goal is to make the gen_models more like true ones\n",
        "        optim_g.zero_grad()\n",
        "        loss = (gen_sample_fake_likelihood - gen_sample_true_likelihood).mean()\n",
        "        loss.backward()\n",
        "        optim_g.step()\n",
        "    print(f\"{game} LikeTrueLoss\", loss.item())\n",
        "    if game % EVERY_REPORT_GAME == 0:\n",
        "        fake_density_pdf = fn.sigmoid(\n",
        "            fake_density_model(torch.Tensor(x_grid).unsqueeze(1)))\n",
        "\n",
        "        fig = visualise_pdf(x_grid, to_numpy_1d(fake_density_pdf), \n",
        "                            samples=to_numpy_1d(fake_x),\n",
        "                            name=\"PDF Fake, Estimated\",\n",
        "                            color=\"#646432\",\n",
        "                            show=False)\n",
        "        fig = visualise_pdf(x_grid, pdf_values, \n",
        "                            name=\"PDF True\",\n",
        "                            fig=fig,\n",
        "                            show=True)\n",
        "    game += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HboC-HbxtHs_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fake_density_pdf = fn.sigmoid(\n",
        "    fake_density_model(torch.Tensor(x_grid).unsqueeze(1)))\n",
        "\n",
        "fig = visualise_pdf(x_grid, to_numpy_1d(fake_density_pdf), \n",
        "                    samples=to_numpy_1d(fake_x),\n",
        "                    name=\"PDF Fake, Estimated\",\n",
        "                    color=\"#646432\",\n",
        "                    show=False)\n",
        "fig = visualise_pdf(x_grid, pdf_values, \n",
        "                    name=\"PDF True\",\n",
        "                    fig=fig,\n",
        "                    show=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-4Fp2QwtHtA",
        "colab_type": "text"
      },
      "source": [
        "### 3.1.3 GAN Framework"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_NfGqMf-tHtA",
        "colab_type": "text"
      },
      "source": [
        "The final piece completing the picture of the generative model framework arises from the following comtemplation. \n",
        "\n",
        "> In the above scheme, we 1) estimated PDF produced by the generator $p(x|fake)$ using generated samples and 2) compared the likelihood of the generated samples under $p(x|fake)$ and $p(x|true)$. This is implemented in the following logic\n",
        "\n",
        "```python\n",
        "gen_sample_fake_likelihood = fake_density_model(fake_x) # estimate fake.prob\n",
        "gen_sample_true_likelihood = logpdf_fn_t(fake_x)        # estimate true.prob\n",
        "...\n",
        "loss = (gen_sample_fake_likelihood - gen_sample_true_likelihood).mean() \n",
        "# diff: make the produced sample look as true as possible\n",
        "```\n",
        "\n",
        "The challenges are\n",
        "- Estimating $p(x|fake)$ is slow and inaccurate.\n",
        "- We don't have $p(x|true)$ in practical scenarios anyway.\n",
        "\n",
        "The essential thoughts are\n",
        "> As far as comparison is concerned, we can employ a *Discriminator* to classify whether a sample is from the true data distribution (a training sample) or a generated one.\n",
        "\n",
        "This makes it no longer necessary \n",
        "- to *explicitly* estimate the PDF $p(x|fake)$ produced by the generator from the fake samples.\n",
        "- to have access to the ground-truth $p(x|true)$.\n",
        "\n",
        "The new framework is as follows.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "code_folding": [
          11
        ],
        "id": "SW7VznRZtHtA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DiscriminatorVanilla(nn.Module):\n",
        "    def __init__(self, hidden_units=2):\n",
        "        super(DiscriminatorVanilla, self).__init__()\n",
        "        self.lin1 = nn.Linear(in_features=1, out_features=hidden_units)\n",
        "        self.lin2 = nn.Linear(in_features=hidden_units, out_features=1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        h = fn.relu(self.lin1(x))\n",
        "        p = torch.sigmoid(self.lin2(h))\n",
        "        return p\n",
        "    \n",
        "class GeneratorVanilla(nn.Module):\n",
        "    def __init__(self, hidden_units):\n",
        "        super(GeneratorVanilla, self).__init__()\n",
        "        self.lin1 = nn.Linear(in_features=1, out_features=hidden_units)\n",
        "        self.lin2 = nn.Linear(in_features=hidden_units, out_features=1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        h = torch.tanh(self.lin1(x))\n",
        "        out = self.lin2(h)\n",
        "        return out\n",
        "    \n",
        "\n",
        "# W-GAN    \n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, hidden_units=4):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.lin1 = nn.Linear(in_features=1, out_features=hidden_units)\n",
        "        self.lin2 = nn.Linear(in_features=hidden_units, \n",
        "                              out_features=hidden_units)\n",
        "        self.lin3 = nn.Linear(in_features=hidden_units, out_features=1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        h = torch.tanh(self.lin1(x))\n",
        "        h = torch.tanh(self.lin2(h))\n",
        "        out = self.lin3(h)\n",
        "        return out\n",
        "    \n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, hidden_units=4):\n",
        "        super(Generator, self).__init__()\n",
        "        self.lin1 = nn.Linear(in_features=1, out_features=hidden_units)\n",
        "        self.bn1 = nn.BatchNorm1d(hidden_units)\n",
        "        self.lin2 = nn.Linear(in_features=hidden_units, \n",
        "                              out_features=hidden_units)\n",
        "        self.bn2 = nn.BatchNorm1d(hidden_units)\n",
        "        self.lin3 = nn.Linear(in_features=hidden_units, out_features=1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        h = self.bn1(torch.tanh(self.lin1(x)))\n",
        "        h = self.bn2(torch.tanh(self.lin2(h)))\n",
        "        out = self.lin3(h)\n",
        "        return out\n",
        "    \n",
        "class GAN:\n",
        "    \"\"\"\n",
        "    Please complete the GAN framework using the example training procedure\n",
        "    provided below.\n",
        "    \"\"\"\n",
        "    def __init__():\n",
        "        self.discrim = Discriminator()\n",
        "        self.gen = Generator()\n",
        "        \n",
        "    \n",
        "    def fit(self, x):\n",
        "        optim_discrim = torch.optim.Adam(self.discrim)\n",
        "        optim_gen = torch.optim.Adam(self.gen)\n",
        "        \n",
        "        for i in range(1000):\n",
        "            # generate fake samples\n",
        "            fake_x = 0\n",
        "            # train discriminator\n",
        "            for j in range(5):\n",
        "                pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAT5Pyt6tHtB",
        "colab_type": "text"
      },
      "source": [
        "Note that we adopted the tricks proposed in Weirstein GAN to stablise and speed up. Read more:\n",
        "[[paper-link](https://arxiv.org/abs/1701.07875)]\n",
        "[[tutorial](https://wiseodd.github.io/techblog/2017/02/04/wasserstein-gan/)]\n",
        "[[tutorial-more-background](https://paper.dropbox.com/doc/Wasserstein-GAN-GvU0p2V9ThzdwY3BbhoP7)]\n",
        "\n",
        "Below are two more videos, one from the original GAN inventor, and the other talks about other generative models.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tI59RE5jleFA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "from IPython.display import YouTubeVideo\n",
        "YouTubeVideo('9JpdAg6uMXs', width=600, height=400)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqpWXQCslxNM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "from IPython.display import YouTubeVideo\n",
        "YouTubeVideo('9zKuYvjFFS8', width=600, height=400)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwAXgg29tHtB",
        "colab_type": "text"
      },
      "source": [
        "We don't use true PDF anymore, instead, we take training samples as in practical machine learning tasks. However, we do not need labels to train generative models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69xAfvrltHtB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_sample_num = 5000\n",
        "train_samples_np = get_gmm_samples(sample_num=train_sample_num, \n",
        "                                   norm_params=ex_gmm_parameters)\n",
        "\n",
        "train_samples = torch.Tensor(train_samples_np).unsqueeze(dim=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwTAClYrtHtC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tqdm\n",
        "# Create the function approximators\n",
        "discrim = Discriminator(16)\n",
        "generator = Generator(16)\n",
        "\n",
        "optim_discrim = torch.optim.Adam(discrim.parameters(), lr=1e-4)\n",
        "optim_gen = torch.optim.Adam(generator.parameters(), lr=1e-4)\n",
        "\n",
        "fake_sample_num = train_sample_num\n",
        "\n",
        "max_train_iters = 20000\n",
        "train_discrim_iters = 5 # W-GAN (more discrim iters)\n",
        "\n",
        "fig = go.Figure([go.Histogram(x=train_samples.numpy().squeeze(), nbinsx=100, \n",
        "                              marker=dict(color=\"red\"))])\n",
        "fig.show()\n",
        "hist_scatters = []\n",
        "for i in range(max_train_iters): #tqdm.tqdm_notebook(range(max_train_iters)):\n",
        "    # generate fake samples\n",
        "    random_inputs = torch.randn(fake_sample_num).unsqueeze(dim=1)\n",
        "    with torch.no_grad():\n",
        "        fake_samples = generator(random_inputs)\n",
        "    \n",
        "    x = torch.cat((train_samples, fake_samples), dim=0)\n",
        "    gnd = torch.cat((torch.ones(train_sample_num),\n",
        "                     torch.zeros(fake_sample_num)))\n",
        "\n",
        "    # train discriminator\n",
        "    for j in range(2):\n",
        "        pred = discrim(x).squeeze()\n",
        "        optim_discrim.zero_grad()\n",
        "        # discriminator loss\n",
        "        loss_discrim = -(pred * (gnd - 0.5) * 2).sum() # (gnd - 0.5) * 2\n",
        "            # gets +1 for true and -1 for fake, so we want\n",
        "            # discriminator generate BIG values for true\n",
        "            # SMALL values for fake samples\n",
        "        loss_discrim.backward()\n",
        "        optim_discrim.step()\n",
        "        # Clip discriminator parameters\n",
        "        for p in discrim.parameters():\n",
        "            p.data.clamp_(-0.01, 0.01)\n",
        "    \n",
        "    gnd = torch.ones(fake_sample_num)\n",
        "    random_inputs = torch.randn(fake_sample_num).unsqueeze(dim=1)\n",
        "    fake_samples = generator(random_inputs)\n",
        "    output = discrim(fake_samples).squeeze()\n",
        "    # generator loss\n",
        "    loss_gen = - output.mean() # We want the generator to make samples\n",
        "        # ~to make discriminator to make BIG values.\n",
        "    optim_gen.zero_grad()\n",
        "    loss_gen.backward()\n",
        "    optim_gen.step()\n",
        "    \n",
        "    \n",
        "    \n",
        "    if i % 1000 == 0:\n",
        "        hist_scatters.append(\n",
        "            go.Histogram(x=fake_samples.detach().numpy().squeeze(), nbinsx=100,\n",
        "                         marker=dict(color=\"blue\"))\n",
        "        )\n",
        "        fig = go.Figure([go.Histogram(x=train_samples.numpy().squeeze(), nbinsx=100, marker=dict(color=\"red\")),\n",
        "                         go.Histogram(x=fake_samples.detach().numpy().squeeze(), nbinsx=100, marker=dict(color=\"blue\"))])\n",
        "        fig.show()\n",
        "        # fig.update()\n",
        "        \n",
        "        \n",
        "        str1 = \"Discriminator loss {:.2f}\".format(loss_discrim.item())\n",
        "        str2 = \"Generator loss {:.2f}\".format(loss_gen.item())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1P6Rht2tHtC",
        "colab_type": "text"
      },
      "source": [
        "## 3.2 Practical Data Generator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tfj0qsOTtHtC",
        "colab_type": "text"
      },
      "source": [
        "### 3.2.0 Preparing Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpzX8WbatHtD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.optim import Adam\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "%matplotlib inline\n",
        "def show(img):\n",
        "    npimg = img.detach().to(\"cpu\").numpy()\n",
        "    npimg -= npimg.min()\n",
        "    npimg /= npimg.max()\n",
        "    if npimg.shape[0] in [3,4]:\n",
        "        plt.imshow(np.transpose(npimg, (1,2,0)), interpolation='nearest')\n",
        "    else:\n",
        "        plt.imshow(npimg.squeeze(), interpolation='nearest')\n",
        "torch.random.manual_seed(1984)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "g_noise_dim=64 # see def of the networks\n",
        "g_basic_channels=64\n",
        "\n",
        "\n",
        "if not os.path.exists(\"./checkpoints\"):\n",
        "    os.makedirs(\"./checkpoints\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7PokdqqtHtD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=True,\n",
        "    download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(\n",
        "    trainset, batch_size=batch_size,\n",
        "    shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=False,\n",
        "    download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(\n",
        "    testset, batch_size=batch_size,\n",
        "    shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "# Check the data\n",
        "for x, y in trainloader:\n",
        "    break\n",
        "print(x.shape)\n",
        "print(y.shape)\n",
        "show(x[0])\n",
        "print(classes[y[0]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXPvUpj2tHtE",
        "colab_type": "text"
      },
      "source": [
        "Let check the generator on practical image data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhNONNBetHtE",
        "colab_type": "text"
      },
      "source": [
        "### 3.2.1 GAN Framework Definition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-hNgEdntHtE",
        "colab_type": "text"
      },
      "source": [
        "#### Image Generator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxxBynALtHtE",
        "colab_type": "text"
      },
      "source": [
        "Note we can control the model complexity by using different numbers of intermediate channels (`basic_channels`). The `TransposedConv` renders information from internal code to image-like outputs. See the [intuitive illustration](https://github.com/vdumoulin/conv_arithmetic)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBPrP1FntHtE",
        "colab_type": "text"
      },
      "source": [
        "We adopt the following practical measures:\n",
        "\n",
        "- batch normalisation\n",
        "- using `relu` for activation in generator (later will use leaky-relu in discriminator)\n",
        "- use `tanh` as output in generator\n",
        "- kernel size = 4\n",
        "\n",
        "The architecture has been proposed by [DCGAN](https://arxiv.org/abs/1511.06434) and had been shown practically useful."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_zuJwEltHtF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GNet_CIFAR(nn.Module):\n",
        "    def __init__(self, noise_dim=64, basic_channels=64):\n",
        "        super(GNet_CIFAR, self).__init__()\n",
        "        self.convtr1 = nn.ConvTranspose2d(\n",
        "            in_channels=noise_dim, \n",
        "            out_channels=basic_channels*4,\n",
        "            kernel_size=4,\n",
        "            stride=1,\n",
        "            padding=0,\n",
        "            bias=False)\n",
        "        self.convtr2 = nn.ConvTranspose2d(\n",
        "            basic_channels*4, basic_channels*2, \n",
        "            kernel_size=4, stride=2, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(basic_channels*2)\n",
        "        self.convtr3 = nn.ConvTranspose2d(\n",
        "            basic_channels*2, basic_channels, \n",
        "            kernel_size=4, stride=2, padding=1, bias=False)\n",
        "        self.convtr4 = nn.ConvTranspose2d(\n",
        "            basic_channels, 3, \n",
        "            kernel_size=4, stride=2, padding=1, bias=False)\n",
        "        \n",
        "        self.bn1 = nn.BatchNorm2d(basic_channels*4)\n",
        "        self.bn2 = nn.BatchNorm2d(basic_channels*2)\n",
        "        self.bn3 = nn.BatchNorm2d(basic_channels)\n",
        "        \n",
        "        \n",
        "    def forward(self, x):\n",
        "        h = self.convtr1(x)\n",
        "        h = self.bn1(h)\n",
        "        h = fn.relu(h)\n",
        "        h = self.convtr2(h)\n",
        "        h = self.bn2(h)\n",
        "        h = fn.relu(h)\n",
        "        h = self.convtr3(h)\n",
        "        h = self.bn3(h)\n",
        "        h = fn.relu(h)\n",
        "        h = self.convtr4(h)\n",
        "        h = torch.tanh(h)\n",
        "        \n",
        "        return h"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxRN2mMftHtF",
        "colab_type": "text"
      },
      "source": [
        "#### Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "de7PVAIrtHtF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DNet_CIFAR(nn.Module):\n",
        "    def __init__(self, basic_channels=64):\n",
        "        super(DNet_CIFAR, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_channels=3, \n",
        "            out_channels=basic_channels,\n",
        "            kernel_size=4)\n",
        "        \n",
        "        self.conv2 = nn.Conv2d(\n",
        "            basic_channels, basic_channels*2, \n",
        "            kernel_size=4)\n",
        "        self.conv3 = nn.Conv2d(\n",
        "            basic_channels*2, basic_channels*4, \n",
        "            kernel_size=4)\n",
        "        self.linear = nn.Linear(1024, 1)\n",
        "        \n",
        "        \n",
        "        self.bn1 = nn.BatchNorm2d(basic_channels*2)\n",
        "        \n",
        "        \n",
        "    def forward(self, x):\n",
        "        h = self.conv1(x)\n",
        "        h = fn.leaky_relu(h, 0.2, inplace=True)\n",
        "        h = fn.max_pool2d(h, 2)\n",
        "        h = self.conv2(h)\n",
        "        h = self.bn1(h)\n",
        "        h = fn.leaky_relu(h, 0.2, inplace=True)\n",
        "        h = fn.max_pool2d(h, 2)\n",
        "        h = self.conv3(h)\n",
        "        h = self.linear(h.view(h.shape[0], -1))\n",
        "        # h = F.sigmoid(h)\n",
        "        return h"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46E-VAMatHtG",
        "colab_type": "text"
      },
      "source": [
        "#### GAN Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g24WVkOCtHtG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dnet = DNet_CIFAR(basic_channels=g_basic_channels).to(device) # device detected in preparation above\n",
        "gnet = GNet_CIFAR(basic_channels=g_basic_channels,\n",
        "                  noise_dim=g_noise_dim).to(device)\n",
        "learning_rate = 1e-4\n",
        "optim_discrim = Adam(dnet.parameters(), lr=learning_rate)\n",
        "optim_gen = Adam(gnet.parameters(), lr=learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jecUJt_tHtG",
        "colab_type": "text"
      },
      "source": [
        "Discriminator trainer.\n",
        "\n",
        "We separate true and fake samples in two batches."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zdlfk7pVtHtG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_ones = torch.ones(batch_size).to(device)\n",
        "y_zeros = torch.zeros(batch_size).to(device)\n",
        "\n",
        "def train_discrim(discrim_train_iters=5):\n",
        "    \"\"\"\n",
        "    Since we will make a GAN class eventually, we will use some\n",
        "    global objects available, including\n",
        "    - trainloader\n",
        "    - opt\n",
        "    - gnet\n",
        "    - dnet\n",
        "    - optim_discrim\n",
        "    - criterion\n",
        "    \"\"\"\n",
        "    for i in range(discrim_train_iters):\n",
        "        optim_discrim.zero_grad()\n",
        "        \n",
        "        x_true, _ = next(iter(trainloader))\n",
        "        pred_1 = dnet(x_true.to(device)).squeeze()\n",
        "        loss_dis_1 = - pred_1.mean() # criterion(pred_1, y_ones)\n",
        "        \n",
        "        \n",
        "        z = torch.randn(batch_size, g_noise_dim, 1, 1).to(device)\n",
        "        x_fake = gnet(z).detach()\n",
        "        pred_2 = dnet(x_fake).squeeze()\n",
        "        loss_dis_2 =  pred_2.mean() # criterion(pred_2, y_zeros)\n",
        "        \n",
        "        loss = loss_dis_1 + loss_dis_2\n",
        "        loss.backward()\n",
        "        optim_discrim.step()\n",
        "        for p in dnet.parameters():\n",
        "                p.data.clamp_(-0.01, 0.01)\n",
        "    \n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhOwUyRbtHtH",
        "colab_type": "text"
      },
      "source": [
        "Generator Trainer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VX6eS-5ttHtH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_gen():\n",
        "    \"\"\"\n",
        "    Global variables\n",
        "    - optim_gen\n",
        "    - gnet\n",
        "    - dnet\n",
        "    - opt\n",
        "    \"\"\"\n",
        "    optim_gen.zero_grad()\n",
        "    z = torch.randn(batch_size*2, g_noise_dim, 1, 1).to(device)\n",
        "    x_fake = gnet(z) #! You cannot detach it NOW!\n",
        "    gen_plausib = dnet(x_fake)\n",
        "    loss_gen = (1.0 - gen_plausib).mean()\n",
        "    loss_gen.backward()\n",
        "    optim_gen.step()\n",
        "    return loss_gen, x_fake"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p64LtkSztHtH",
        "colab_type": "text"
      },
      "source": [
        "Perform training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kffULWGtHtH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import Image, display\n",
        "iters = 0\n",
        "while iters<15000:\n",
        "    loss_dis = train_discrim()\n",
        "    loss_gen, x_fake = train_gen()\n",
        "    \n",
        "    if iters % 100==0:\n",
        "        print(\"{:d} steps: Loss D: {:.3f} G: {:.3f} +:{:.3f}\".format(\n",
        "            iters, loss_dis, loss_gen, loss_dis+loss_gen\n",
        "        ))\n",
        "\n",
        "    if iters % 1000 == 0:\n",
        "        torch.save(dnet.state_dict(), f\"./checkpoints/D{iters:06d}.pt\")\n",
        "        torch.save(dnet.state_dict(), f\"./checkpoints/G{iters:06d}.pt\")\n",
        "        torchvision.utils.save_image(x_fake, \n",
        "                                     f\"./checkpoints/gen{iters:06d}.png\", \n",
        "                                     normalize=True)\n",
        "        display(Image(filename=f\"./checkpoints/gen{iters:06d}.png\"))\n",
        "        print(f\"Iter {iters}, models saved.\")\n",
        "        # show(x_fake[0])\n",
        "    iters+=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cnjbuxQclo2",
        "colab_type": "text"
      },
      "source": [
        "## 3.3 Image Transformation GAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ji67rRQrckO0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import functools\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import make_grid\n",
        "\n",
        "image_transform = transforms.Compose([\n",
        "            transforms.Resize((256, 256), Image.BICUBIC),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5, 0.5, 0.5),\n",
        "                                 (0.5, 0.5, 0.5))])\n",
        "\n",
        "to_pil = transforms.Compose([\n",
        "    transforms.Normalize((-1.0, -1.0, -1.0), (2.0, 2.0, 2.0)),\n",
        "    transforms.ToPILImage()])\n",
        "\n",
        "\n",
        "def load_image(image_path):\n",
        "    A_img = Image.open(image_path).convert('RGB')\n",
        "    return image_transform(A_img).unsqueeze(0)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Defines the generator that consists of Resnet blocks between a few\n",
        "# downsampling/upsampling operations.\n",
        "# Code and idea originally from Justin Johnson's architecture.\n",
        "# https://github.com/jcjohnson/fast-neural-style/\n",
        "class ResnetGenerator(nn.Module):\n",
        "    def __init__(self, input_nc, output_nc, ngf=64, norm_layer=nn.BatchNorm2d,\n",
        "                 use_dropout=False, n_blocks=6, padding_type='reflect'):\n",
        "        assert(n_blocks >= 0)\n",
        "        super(ResnetGenerator, self).__init__()\n",
        "        self.input_nc = input_nc\n",
        "        self.output_nc = output_nc\n",
        "        self.ngf = ngf\n",
        "        if type(norm_layer) == functools.partial:\n",
        "            use_bias = norm_layer.func == nn.InstanceNorm2d\n",
        "        else:\n",
        "            use_bias = norm_layer == nn.InstanceNorm2d\n",
        "\n",
        "        model = [nn.ReflectionPad2d(3),\n",
        "                 nn.Conv2d(input_nc, ngf, kernel_size=7, padding=0,\n",
        "                           bias=use_bias),\n",
        "                 norm_layer(ngf),\n",
        "                 nn.ReLU(True)]\n",
        "\n",
        "        n_downsampling = 2\n",
        "        for i in range(n_downsampling):\n",
        "            mult = 2**i\n",
        "            model += [nn.Conv2d(ngf * mult, ngf * mult * 2, kernel_size=3,\n",
        "                                stride=2, padding=1, bias=use_bias),\n",
        "                      norm_layer(ngf * mult * 2),\n",
        "                      nn.ReLU(True)]\n",
        "\n",
        "        mult = 2**n_downsampling\n",
        "        for i in range(n_blocks):\n",
        "            model += [ResnetBlock(ngf * mult, padding_type=padding_type, norm_layer=norm_layer, use_dropout=use_dropout, use_bias=use_bias)]\n",
        "\n",
        "        for i in range(n_downsampling):\n",
        "            mult = 2**(n_downsampling - i)\n",
        "            model += [nn.ConvTranspose2d(ngf * mult, int(ngf * mult / 2),\n",
        "                                         kernel_size=3, stride=2,\n",
        "                                         padding=1, output_padding=1,\n",
        "                                         bias=use_bias),\n",
        "                      norm_layer(int(ngf * mult / 2)),\n",
        "                      nn.ReLU(True)]\n",
        "        model += [nn.ReflectionPad2d(3)]\n",
        "        model += [nn.Conv2d(ngf, output_nc, kernel_size=7, padding=0)]\n",
        "        model += [nn.Tanh()]\n",
        "\n",
        "        self.model = nn.Sequential(*model)\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.model(input)\n",
        "\n",
        "\n",
        "# Define a resnet block\n",
        "class ResnetBlock(nn.Module):\n",
        "    def __init__(self, dim, padding_type, norm_layer, use_dropout, use_bias):\n",
        "        super(ResnetBlock, self).__init__()\n",
        "        self.conv_block = self.build_conv_block(dim, padding_type, norm_layer, use_dropout, use_bias)\n",
        "\n",
        "    def build_conv_block(self, dim, padding_type, norm_layer, use_dropout, use_bias):\n",
        "        conv_block = []\n",
        "        p = 0\n",
        "        if padding_type == 'reflect':\n",
        "            conv_block += [nn.ReflectionPad2d(1)]\n",
        "        elif padding_type == 'replicate':\n",
        "            conv_block += [nn.ReplicationPad2d(1)]\n",
        "        elif padding_type == 'zero':\n",
        "            p = 1\n",
        "        else:\n",
        "            raise NotImplementedError('padding [%s] is not implemented' % padding_type)\n",
        "\n",
        "        conv_block += [nn.Conv2d(dim, dim, kernel_size=3, padding=p, bias=use_bias),\n",
        "                       norm_layer(dim),\n",
        "                       nn.ReLU(True)]\n",
        "        if use_dropout:\n",
        "            conv_block += [nn.Dropout(0.5)]\n",
        "\n",
        "        p = 0\n",
        "        if padding_type == 'reflect':\n",
        "            conv_block += [nn.ReflectionPad2d(1)]\n",
        "        elif padding_type == 'replicate':\n",
        "            conv_block += [nn.ReplicationPad2d(1)]\n",
        "        elif padding_type == 'zero':\n",
        "            p = 1\n",
        "        else:\n",
        "            raise NotImplementedError('padding [%s] is not implemented' % padding_type)\n",
        "        conv_block += [nn.Conv2d(dim, dim, kernel_size=3, padding=p, bias=use_bias),\n",
        "                       norm_layer(dim)]\n",
        "\n",
        "        return nn.Sequential(*conv_block)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = x + self.conv_block(x)\n",
        "        return out\n",
        "\n",
        "def create_generator():\n",
        "    norm_layer = functools.partial(nn.InstanceNorm2d, affine=False,\n",
        "                                   track_running_stats=True)\n",
        "    netG = ResnetGenerator(3, 3, 64, norm_layer=norm_layer, use_dropout=False,\n",
        "                           n_blocks=9)\n",
        "    return netG\n",
        "\n",
        "def get_trained_model_parameters(style):\n",
        "    import urllib\n",
        "    if not os.path.exists(\"checkpoints/\"):\n",
        "        os.makedirs(\"checkpoints\")\n",
        "    model_path = f\"checkpoints/style_{style}.pth\"\n",
        "    if not os.path.exists(model_path):\n",
        "        urllib.request.urlretrieve(\n",
        "            \"http://efrosgans.eecs.berkeley.edu/cyclegan/pretrained_models/\"\n",
        "            + 'style_' + style + \".pth\",\n",
        "            model_path)\n",
        "    return model_path\n",
        "\n",
        "def __patch_instance_norm_state_dict(state_dict, module, keys, i=0):\n",
        "    key = keys[i]\n",
        "    if i + 1 == len(keys):  # at the end, pointing to a parameter/buffer\n",
        "        if module.__class__.__name__.startswith('InstanceNorm') and \\\n",
        "                (key == 'running_mean' or key == 'running_var'):\n",
        "            if getattr(module, key) is None:\n",
        "                state_dict.pop('.'.join(keys))\n",
        "        if module.__class__.__name__.startswith('InstanceNorm') and \\\n",
        "           (key == 'num_batches_tracked'):\n",
        "            state_dict.pop('.'.join(keys))\n",
        "    else:\n",
        "        __patch_instance_norm_state_dict(\n",
        "            state_dict, getattr(module, key), keys, i + 1)\n",
        "\n",
        "def load_generator_from(netG, model_path):\n",
        "    state_dict = torch.load(model_path)\n",
        "    for key in list(\n",
        "            state_dict.keys()):  # need to copy keys because we mutate in loop\n",
        "        __patch_instance_norm_state_dict(state_dict, netG, key.split('.'))\n",
        "    netG.load_state_dict(state_dict)\n",
        "    return netG    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUiQ4Iuojv2Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Parameter setting\n",
        "#@markdown Choose an artist's style to play with\n",
        "style = \"cezanne\" #@param [\"cezanne\", \"monet\", \"ukiyoe\", \"vangogh\"] {allow-input: false}\n",
        "#@markdown ---\n",
        "model_path = get_trained_model_parameters(style)\n",
        "image_transf_net = create_generator()\n",
        "image_transf_net = load_generator_from(image_transf_net, model_path).to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_lKlszVsXCV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_image_fname = \"/content/rose-blue-flower-rose-blooms-67636.jpeg\"\n",
        "assert os.path.exists(input_image_fname), \\\n",
        "    (\"Image file does not exist, upload one and copy \"\n",
        "    \"the path using the panel on left.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDjJae_ArWcB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Alternatively, you can make a selfy here 👩🏻🤳 :P"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyh4ikuxkn_0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "im0 = load_image(input_image_fname).to(device)\n",
        "im1 = image_transf_net(im0)\n",
        "im_display = make_grid(torch.cat((im0, im1)).cpu())\n",
        "to_pil(im_display)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}